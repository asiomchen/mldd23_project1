{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b935edfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gru.gru_v3 import EncoderDecoder\n",
    "from gru.dataset import GRUDataset\n",
    "from gru.cce import ConsciousCrossEntropy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from vectorizer import SELFIESVectorizer, determine_alphabet\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = EncoderDecoder\n",
    "\n",
    "device = 'cuda'\n",
    "print(device)\n",
    "\n",
    "# Set hyperparameters\n",
    "encoding_size = 512\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "learn_rate = 0.0003\n",
    "dropout = 0 # dropout must be equal 0 if num_layers = 1\n",
    "teacher_ratio = 0.5\n",
    "\n",
    "# Init model\n",
    "model = EncoderDecoder(\n",
    "    fp_size=4860,\n",
    "    encoding_size=encoding_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    teacher_ratio = teacher_ratio).to(device)\n",
    "\n",
    "alphabet = pd.read_csv('./GRU_data/alphabet.txt', header=None).values.flatten()\n",
    "\n",
    "#model.load_state_dict(torch.load('PATH'))\n",
    "model.load_state_dict(torch.load('./models/v3-revisited/model_epoch_14.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfcedc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 121524\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_parquet('./GRU_data/test_dataset.parquet').reset_index().drop(columns='index')\n",
    "vectorizer = SELFIESVectorizer(alphabet, pad_to_len=128)\n",
    "test_dataset = GRUDataset(test_df, vectorizer)\n",
    "\n",
    "print(\"Test size:\", len(test_dataset))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 256\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c079d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x, y, teacher_forcing=False)\n",
    "softmax = nn.Softmax(dim=2)\n",
    "out = softmax(out)\n",
    "out = out.detach().cpu().numpy()\n",
    "target = y.detach().cpu().numpy()\n",
    "fps = x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2818f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import rdkit.Chem as Chem\n",
    "\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "preds_selfies = []\n",
    "targets_selfies = []\n",
    "\n",
    "for n in range(batch_size):\n",
    "    selfie_out = vectorizer.devectorize(out[n], remove_special=True)\n",
    "    preds_selfies.append(selfie_out)\n",
    "    selfie_target = vectorizer.devectorize(target[n], remove_special=True)\n",
    "    targets_selfies.append(selfie_target)\n",
    "    smiles_out = sf.decoder(selfie_out)\n",
    "    smiles_target = sf.decoder(selfie_target)\n",
    "    mol_out = Chem.MolFromSmiles(smiles_out)\n",
    "    mol_target = Chem.MolFromSmiles(smiles_target)\n",
    "    preds.append(mol_out)\n",
    "    targets.append(mol_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75b0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = pd.read_csv('KlekFP_keys.txt', header=None, names=['smarts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd53d675",
   "metadata": {},
   "outputs": [],
   "source": [
    " from ipywidgets import interact_manual, interact\n",
    "import rdkit.Chem.Draw.IPythonConsole as IpythonConsole\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import numpy as np\n",
    "\n",
    "IPythonConsole.molSize = 500,500\n",
    "\n",
    "fps = x.cpu().numpy()\n",
    "\n",
    "def highlight(idx, fp_bit):\n",
    "    target_mol = targets[idx]\n",
    "    pred_mol = preds[idx]\n",
    "    fp = fps[idx]\n",
    "    fp_idxised = idxise_fp(fp)\n",
    "    print(fp_idxised)\n",
    "    substructure = Chem.MolFromSmarts(key.smarts[fp_bit])\n",
    "    target_mol.GetSubstructMatches(substructure)\n",
    "    return(target_mol)\n",
    "    \n",
    "def idxise_fp(fp):\n",
    "    fps_idxised = []\n",
    "    for i in range(len(fp)):\n",
    "        if fp[i] == 1:\n",
    "            fps_idxised.append(i)\n",
    "    return(fps_idxised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b728d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
