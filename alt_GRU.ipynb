{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6ef6f3f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1686162931150,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "6ef6f3f5",
    "outputId": "b7ffd9f9-98f1-4977-8fed-0201cd7e382b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16dfcb1",
   "metadata": {
    "id": "f16dfcb1"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "8a3fbcdb",
   "metadata": {
    "id": "8a3fbcdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alphabet of tokens for output\n",
    "\n",
    "import selfies as sf\n",
    "data = pd.read_csv('./GRU_data/250k_selfies.csv')\n",
    "alphabet = sf.get_alphabet_from_selfies(data.selfies)\n",
    "alphabet.add(\"[start]\")\n",
    "alphabet.add(\"[end]\")\n",
    "alphabet.add(\"[nop]\") # [nop] is a special padding symbol\n",
    "alphabet = list(sorted(alphabet))\n",
    "#pad_to_len = max(sf.len_selfies(s) for s in data.selfies) + 10\n",
    "pad_to_len = 128 # for simplicities' sake\n",
    "symbol_to_idx = {s: i for i, s in enumerate(alphabet)}\n",
    "idx2char = {i: s for i, s in enumerate(alphabet)}\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f55a6d94",
   "metadata": {
    "id": "f55a6d94"
   },
   "outputs": [],
   "source": [
    "class SELFIESVectorizer:\n",
    "    def __init__(self, alphabet, pad_to_len=None):\n",
    "        self.alphabet = alphabet\n",
    "        self.char2idx = {s: i for i, s in enumerate(alphabet)}\n",
    "        self.idx2char = {i: s for i, s in enumerate(alphabet)}\n",
    "        self.pad_to_len = pad_to_len\n",
    "    def vectorize(self, selfie, no_special=False):\n",
    "        ''' Vectorize a list of SMILES strings to a numpy array of shape (len(smiles), embed, len(charset))'''\n",
    "        if no_special:\n",
    "            splited = self.split_selfi(selfie)\n",
    "        elif self.pad_to_len is None:\n",
    "            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]']\n",
    "        else:\n",
    "            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]'] + ['[nop]'] * (self.pad_to_len - len(self.split_selfi(selfie)) - 2)\n",
    "        X = np.zeros((len(splited), len(self.alphabet)))\n",
    "        for i in range(len(splited)):\n",
    "            X[i, self.char2idx[splited[i]]] = 1\n",
    "        return X\n",
    "    def devectorize(self, ohe, remove_special=False):\n",
    "        ''' Devectorize a numpy array of shape (len(smiles), embed, len(charset)) to a list of SMILES strings'''\n",
    "        selfie_str = ''\n",
    "        for j in range(ohe.shape[0]):\n",
    "            idx = np.argmax(ohe[j, :])\n",
    "            if remove_special and (self.idx2char[idx] == '[start]' or self.idx2char[idx] == '[end]'):\n",
    "                continue\n",
    "            selfie_str += self.idx2char[idx]\n",
    "        return selfie_str\n",
    "    def idxize(self, selfie, no_special=False):\n",
    "        if no_special:\n",
    "            splited = self.split_selfi(selfie)\n",
    "        else:\n",
    "            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]'] + ['[nop]'] * (self.pad_to_len - len(self.split_selfi(selfie)) - 2)\n",
    "        return np.array([self.char2idx[s] for s in splited])\n",
    "    def deidxize(self, idx):\n",
    "        return \"\".join([self.idx2char[i] for i in idx])\n",
    "    def split_selfi(self, selfie):\n",
    "        pattern = r'(\\[[^\\[\\]]*\\])'\n",
    "        return re.findall(pattern, selfie)\n",
    "vectorizer = SELFIESVectorizer(alphabet, pad_to_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "6538d564",
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1686161079219,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "6538d564"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GRUDatasetv2(Dataset):\n",
    "    def __init__(self, smiles_fp, selfies, vectorizer):\n",
    "        self.smiles_fp = pd.read_csv(smiles_fp, nrows=50000)\n",
    "        self.selfies = pd.read_csv(selfies, nrows=50000)\n",
    "        #self.smiles_fp = pd.read_csv(smiles_fp)\n",
    "        #self.selfies = pd.read_csv(selfies)\n",
    "        self.selfies= self.prepare_y(self.selfies)\n",
    "        self.vectorizer = vectorizer\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_fp)\n",
    "    def __getitem__(self, idx):\n",
    "        raw_selfie = self.selfies[idx][0]\n",
    "        vectorized_selfie = self.vectorizer.vectorize(raw_selfie)\n",
    "        raw_X = self.smiles_fp.fps[idx]\n",
    "        X = np.array(eval(raw_X), dtype=int)\n",
    "        X_reconstructed = self.reconstruct_fp(X)\n",
    "        return torch.from_numpy(X_reconstructed).float(), torch.from_numpy(vectorized_selfie).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_X(smiles_fp):\n",
    "        fps = smiles_fp.fps.apply(eval).apply(lambda x: np.array(x, dtype=int))\n",
    "        return fps\n",
    "    @staticmethod\n",
    "    def prepare_y(selfies):\n",
    "        return selfies.values\n",
    "        \n",
    "    @staticmethod\n",
    "    def reconstruct_fp(fp, length=4860):\n",
    "        fp_rec = np.zeros(length)\n",
    "        fp_rec[fp] = 1\n",
    "        return fp_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "062168b4",
   "metadata": {
    "executionInfo": {
     "elapsed": 2163,
     "status": "ok",
     "timestamp": 1686161083709,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "062168b4"
   },
   "outputs": [],
   "source": [
    "dataset = GRUDatasetv2('./GRU_data/250k_klek.csv', './GRU_data/250k_selfies.csv', vectorizer)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "3a16a986",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1686161085877,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "3a16a986",
    "outputId": "f2bde771-1321-4a4e-c72a-0a5f4f60dcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 50000\n",
      "Train size: 45000\n",
      "Test size: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "da4f014e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1686162674319,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "da4f014e",
    "outputId": "5da54a79-6a1d-4b5f-b477-f3da58ba7479"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39daf",
   "metadata": {
    "id": "02f39daf"
   },
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "8248e95c",
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1686162875733,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "8248e95c"
   },
   "outputs": [],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self, fp_size):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(fp_size, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.relu(self.fc4(out))\n",
    "        #out.shape = [batch_size, 256]\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(DecoderNet, self).__init__()\n",
    "        \n",
    "        # GRU parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # output token count\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # pytorch.nn\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        #x.shape = [batch_size, selfie_len, encoding_size] = [64, 128, 256]\n",
    "        out, h = self.gru(x, h)\n",
    "        #out.shape = [batch_size, selfie_len, hidden_size] = [64, 128, 256]\n",
    "        #h.shape = [num_layers, batch_size, hidden_size] = [1, 64, 256]\n",
    "        out1 = self.fc(self.relu(out))\n",
    "        out1 = self.softmax(out1)\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "ea11abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, fp_size=4860, input_size=256, hidden_size=256, num_layers=1, output_size=42):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = EncoderNet(fp_size=4860)\n",
    "        self.decoder = DecoderNet(input_size, hidden_size, num_layers, output_size)\n",
    "        \n",
    "        #pytorch.nn\n",
    "        self.fc = nn.Linear(256, 42)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = decoder.init_hidden(batch_size=x.shape[0]).to(device)\n",
    "        encoded = self.encoder(x)\n",
    "        x = encoded.unsqueeze(1)\n",
    "        decoded = []\n",
    "        for n in range(128):\n",
    "            out, hidden = self.decoder(x, hidden)\n",
    "            x = out\n",
    "            out = self.relu(self.fc(out))\n",
    "            decoded.append(out)\n",
    "        out_cat = torch.cat(decoded, dim=1)\n",
    "        return out_cat # shape [batch_size, selfie_len, alphabet_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0cf5ff",
   "metadata": {},
   "source": [
    "#  NN Debugging section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "c0132236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder and decoder\n",
    "\n",
    "encoder = EncoderNet(fp_size=4860)\n",
    "decoder = DecoderNet(input_size=256, hidden_size=256, num_layers=1, output_size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "a49b4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([256, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "# get test batch, encode and reshape\n",
    "\n",
    "test_src = next(iter(train_loader))[0]\n",
    "test_trg = next(iter(train_loader))[1]\n",
    "encoded = encoder(test_src)\n",
    "encoded = encoded.unsqueeze(1)\n",
    "print(f'Encoded shape: {encoded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "aeea732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(256, 42)\n",
    "relu = nn.ReLU()\n",
    "softmax2d = nn.Softmax(dim=2)\n",
    "\n",
    "hidden = decoder.init_hidden(batch_size)\n",
    "x = encoded\n",
    "decoded = []\n",
    "for n in range(128):\n",
    "    out, hidden = decoder(x, hidden)\n",
    "    x = out\n",
    "    out = relu(fc(out))\n",
    "    decoded.append(out)\n",
    "out_cat = torch.cat(decoded, dim=1)\n",
    "out_cat = softmax(out_cat)\n",
    "out_cat = torch.argmax(out_cat, dim=2)\n",
    "out_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "f2893d40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1686162879520,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "f2893d40",
    "outputId": "24411adf-29bd-4fb1-b572-48812a6e464f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src shape: torch.Size([256, 4860])\n",
      "Trg shape: torch.Size([256, 128, 42])\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder().to(device)\n",
    "test_src = next(iter(train_loader))[0].to(device)\n",
    "test_trg = next(iter(train_loader))[1].to(device)\n",
    "print(f'Src shape: {test_src.shape}')\n",
    "print(f'Trg shape: {test_trg.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "66ead312",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1686162883547,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "F6-wuiP4QNU8",
    "outputId": "412eb4f3-32e4-440c-ea6a-cdf12cf767a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([256, 128, 42])\n",
      "Outputs shape after argmax: (256, 128)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(test_src)\n",
    "print(f'Outputs shape: {outputs.shape}')\n",
    "\n",
    "output = torch.argmax(outputs, dim=2)\n",
    "output = output.detach().numpy()\n",
    "print(f'Outputs shape after argmax: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "041a1163",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1686162892070,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "041a1163",
    "outputId": "4ba3c403-0bea-4440-9230-40ec7bee9414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#N][#N][#N][#N][#N][#N][#N][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1] \n",
      "\n",
      "[#N][#N][#N][#N][#N][#N][#N][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1] \n",
      "\n",
      "[#N][#N][#N][#N][#N][#N][#N][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1] \n",
      "\n",
      "[#N][#N][#N][#N][#N][#N][#N][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1] \n",
      "\n",
      "[#N][#N][#N][#N][#N][#N][#N][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1][#Branch1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see SELFIES\n",
    "selfies = []\n",
    "for selfie in output[:5]:\n",
    "    vectorized = []\n",
    "    for token in selfie:\n",
    "        v = np.zeros(42)\n",
    "        v[token] = 1\n",
    "        vectorized.append(v)\n",
    "    vectorized = np.array(vectorized)\n",
    "    selfie = vectorizer.devectorize(vectorized)\n",
    "    selfies.append(selfie)\n",
    "for selfie in selfies:\n",
    "    print(selfie, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f697df",
   "metadata": {
    "id": "c3f697df"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "def train(train_loader, test_loader, device):\n",
    "\n",
    "    # Setting common hyperparameters\n",
    "    EPOCHS = 10\n",
    "    input_size = 256\n",
    "    hidden_size = 256\n",
    "    n_layers = 1\n",
    "    output_size = 42\n",
    "    learn_rate = 0.001\n",
    "    \n",
    "    # Define dataframe for training progess display\n",
    "    epochs_range = range(1,EPOCHS+1)\n",
    "    metrics = pd.DataFrame();\n",
    "    metrics['epoch'] = epochs_range\n",
    "    \n",
    "    # Define pyplot for plotting metrics\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(7, 3), layout=\"constrained\")\n",
    "    dh = display.display(fig, display_id=True)\n",
    "    \n",
    "    # Instantiating the model\n",
    "    model = EncoderDecoder().to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of GRU\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Start training loop\n",
    "    for epoch in epochs_range:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_idx, (X,y) in enumerate(tqdm(train_loader)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        val_loss = evaluate(model, test_loader)\n",
    "        model.train()\n",
    "\n",
    "        # Update metrics df\n",
    "        metrics = metrics.append({'epoch': epoch, 'train_loss': avg_loss, \n",
    "                                  'val_loss': val_loss}, ignore_index=True)\n",
    "        \n",
    "        # Display metrics\n",
    "        ax[0].clear()\n",
    "        ax[0].plot(metrics.epoch, metrics.train_loss)\n",
    "        ax[0].set_title('training loss')\n",
    "        ax[0].set_xlabel('epoch')\n",
    "        ax[0].set_ylabel('CrossEntropy')\n",
    "        ax[1].clear()\n",
    "        ax[1].plot(metrics.epoch, metrics.val_loss)\n",
    "        ax[1].set_title('validation loss')\n",
    "        ax[1].set_xlabel('epoch')\n",
    "        ax[1].set_ylabel('CrossEntropy')\n",
    "        dh.update(fig)\n",
    "    plt.close()\n",
    "    return model\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (X, y) in enumerate(test_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        epoch_loss += loss.item()\n",
    "    avg_loss = epoch_loss / len(test_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874519b",
   "metadata": {},
   "source": [
    "# Init and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "0839d044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "executionInfo": {
     "elapsed": 1483,
     "status": "error",
     "timestamp": 1686162903542,
     "user": {
      "displayName": "Hubert Rybka",
      "userId": "05494656428041101228"
     },
     "user_tz": -120
    },
    "id": "0839d044",
    "outputId": "ea7a5487-849c-4115-cc43-6b255ea102d2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                       | 10/175 [00:23<06:33,  2.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[591], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[588], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     38\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[549], line 14\u001b[0m, in \u001b[0;36mGRUDatasetv2.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 14\u001b[0m     raw_selfie \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselfies\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m     vectorized_selfie \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mvectorize(raw_selfie)\n\u001b[1;32m     16\u001b[0m     raw_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmiles_fp\u001b[38;5;241m.\u001b[39mfps[idx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8614d46",
   "metadata": {
    "id": "f8614d46"
   },
   "outputs": [],
   "source": [
    "# save model just in case\n",
    "torch.save(model.state_dict(), './GRU_data/test1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad90c0",
   "metadata": {
    "id": "2bad90c0"
   },
   "outputs": [],
   "source": [
    "#loaded_model = Autoencoder(4860, 300, 300, 42, 2, 0.0).to(device)\n",
    "#loaded_model.load_state_dict(torch.load('./GRU_data/model_h300_e500_teacher_forcing.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e768d4a",
   "metadata": {
    "id": "2e768d4a"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "x = x.to(device)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdfd19",
   "metadata": {
    "id": "9dbdfd19"
   },
   "outputs": [],
   "source": [
    "encoded, decoded = loaded_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6bfa9",
   "metadata": {
    "id": "bfe6bfa9"
   },
   "source": [
    "# GRU output to SELFIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab1202",
   "metadata": {
    "id": "2aab1202"
   },
   "outputs": [],
   "source": [
    "decoded_indices = torch.argmax(decoded.cpu(), dim=2)\n",
    "decoded_indices = decoded_indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1d92f",
   "metadata": {
    "id": "c4a1d92f"
   },
   "outputs": [],
   "source": [
    "# set largers value to 1 and others to 0\n",
    "decoded_indices = torch.argmax(decoded.cpu(), dim=2)\n",
    "decoded_indices = decoded_indices.numpy()\n",
    "selfies_out = []\n",
    "for i, original in zip(decoded_indices, y):\n",
    "    vectorized = []\n",
    "    #print(f'Decoded: {i}')\n",
    "    #convert to one-hot\n",
    "    for number in i:\n",
    "        v = np.zeros(42)\n",
    "        v[number] = 1\n",
    "        vectorized.append(v)\n",
    "    vectorized = np.array(vectorized)\n",
    "    selfies_out.append(vectorizer.devectorize(vectorized, remove_special=True))\n",
    "    print(f'Original: {vectorizer.devectorize(original.cpu().numpy())} \\n')\n",
    "    print(f'Decoded:  {vectorizer.devectorize(vectorized)}')\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efcd595",
   "metadata": {
    "id": "1efcd595"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "smiles = []\n",
    "for selfie in selfies_out:\n",
    "    smile = sf.decoder(selfie, attribute=False)\n",
    "    smiles.append(smile)\n",
    "\n",
    "ms = []\n",
    "for smile in smiles:\n",
    "    ms.append(Chem.MolFromSmiles(smile))\n",
    "Draw.MolToImage(ms[5], size=(800, 800), kekulize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
