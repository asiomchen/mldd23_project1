{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import time\n",
    "from rdkit import Chem\n",
    "from fp_gen import KlekFPGenerator, MACCSFPGenerator, SubFPGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def could_be_valid(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol is not None\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_dense(sparse):\n",
    "    return np.nonzero(sparse)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SMILES      Ki\n",
      "0                                               SMILES    \"Ki\"\n",
      "1                        COc1ccc2occ3CC[C@@H](CN)c1c23   860.0\n",
      "2                  CN1CCc2cccc-3c2[C@H]1Cc1cccc(C)c-31    14.4\n",
      "3                    CN(C)[C@@H]1Cc2cccc3nc(O)n(C1)c23    92.0\n",
      "4                  CCCN1CCC2[C@@H]1CCc1cccc(C(N)=O)c21    17.0\n",
      "..                                                 ...     ...\n",
      "995  Cl.COc1ccc2c(c1)oc1c(CN3CCN(CC3)c3ccccc3OC)ccc...    24.0\n",
      "996   Fc1ccc2cccc(N3CCN(CCCOc4ccc5CNC(=O)c5c4)CC3)c2c1  0.0447\n",
      "997  FC(F)(F)c1cccc(c1)N1CCN(CCN2C(=O)CC3(CCCC3)CC2...    8.22\n",
      "998  Cl.COc1ccc2c(c1)oc1ccc(CN3CCN(CC3)c3ccccc3OC)c...   429.0\n",
      "999  CNC(=O)c1ccc2[C@@H](CCN3CCN(CC3)c3ccc(OC)cc3)O...  3356.0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:17:38] SMILES Parse Error: syntax error while parsing: SMILES\n",
      "[11:17:38] SMILES Parse Error: Failed parsing SMILES 'SMILES' for input: 'SMILES'\n",
      "C:\\Users\\matit\\AppData\\Local\\Temp\\ipykernel_12524\\1485409639.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['fps'] = list(map(sparse_to_dense, fps))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 SMILES       Ki\n",
      "1000  O=S(=O)(N1CCC[C@H]1CCN1CCN(CC1)c1nsc2ccccc12)c...    37.00\n",
      "1001         Fc1ccc(cc1)C(=O)CCCN1CCCN(CC1)c1ccc(Cl)cc1   117.40\n",
      "1002       Clc1ccc(cc1)C1=CCN(CCN2C(=O)c3ccccc3C2=O)CC1   631.00\n",
      "1003          C(CNCCOc1cccc2[nH]cnc12)Cc1c[nH]c2ccccc12     0.87\n",
      "1004       OC(COCc1ccccc1)CN1CCC2(CC1)OCc1c2ccc2ccccc12     2.20\n",
      "...                                                 ...      ...\n",
      "1995  Clc1cccc(c1)S(=O)(=O)NCCN1CCC(=CC1)c1c[nH]c2cc...     7.40\n",
      "1996       CC1CCN(CC[C@H]2CCCN2S(=O)(=O)c2cccc(C)c2)CC1  1000.00\n",
      "1997  CCCCOC(=O)c1cc2c3OC(CN4CCC5(CC4)N(CNC5=O)c4ccc...     3.00\n",
      "1998            COc1cccc2c(CCCN3CCN(CC3)c3ccccn3)cccc12     0.38\n",
      "1999               COc1cccc2CC[C@@H]3[C@H](CCN3CC=C)c12     4.70\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                                 SMILES        Ki\n",
      "2000      CN1C(=N)N(C)\\\\C(=C\\\\c2c[nH]c3c(Br)cccc23)C1=O  1812.000\n",
      "2001       CC1(C)CC(=O)N(CCN2CCN(CC2)c2ccccc2Cl)C(=O)C1    65.800\n",
      "2002                      CCCCCCCOc1ccc2[nH]cc(CCN)c2c1    38.000\n",
      "2003  Cc1ccc2c(cccc2n1)N1CCN(CCc2cccc(c2)N2CCCOC2=O)CC1     2.512\n",
      "2004  COc1ccc(cc1)-c1ccccc1N1CCN(CCCCOc2ccc3OC(C)C(=...   127.000\n",
      "...                                                 ...       ...\n",
      "2995       Cl.Cl.COc1ccccc1N1CCN(CCOCCOc2cccc(C)c2C)CC1     5.000\n",
      "2996  Clc1ccc(s1)S(=O)(=O)NC1CCN(CCOc2ccccc2-c2ccccc...   190.000\n",
      "2997  NC(=O)[C@@H]1Cc2ccccc2CN1C(=O)CCCCN1CCN(CC1)c1...       NaN\n",
      "2998          COc1cc2CCN3Cc4c(OC)ccc(OC)c4C[C@H]3c2cc1O   493.480\n",
      "2999                     CCCN1CCC2Cc3c(O)cccc3C[C@@H]12    62.000\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                                 SMILES        Ki\n",
      "3000    Cc1ccc2c(cccc2n1)N1CCN(CCc2cccc3NC(=O)COc23)CC1    0.2512\n",
      "3001  CN1C(=O)COc2c(CCN3CCN(CC3)c3cccc4nc(C)ccc34)cc...    0.1585\n",
      "3002      CCN(CC)CCc1c[nH]c2ccc(OS(=O)(=O)C(F)(F)F)cc12   27.0000\n",
      "3003  CSc1ccccc1N1CCN(Cc2ccc(cc2)C(=O)N2CCC[C@H]2C(N...  313.0000\n",
      "3004    CC(C)c1ccccc1OCCN1CCC(CC1)NS(=O)(=O)c1ccc(N)cc1  502.0000\n",
      "...                                                 ...       ...\n",
      "3995                COc1cccc2C[C@H]3CCN(CC=C)[C@H]3Cc12  145.0000\n",
      "3996  CC(=O)c1c(OCCCN2CCN(CC2)c2ccccc2F)ccc2c(C)cc(=...    1.3000\n",
      "3997             Fc1ccc(CCCCN2CCCN(CC2)c2ccc(Cl)cc2)cc1   91.0000\n",
      "3998                          CCCCCN1CCC(C1)c1cccc(O)c1  326.0000\n",
      "3999                        CCCCCCCN1CCC(C1)c1cccc(O)c1   19.0000\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                                 SMILES       Ki\n",
      "4000               OC12C3C4C5C3C(C3C5CC4C13)N2CC1CCCCC1      NaN\n",
      "4001  Fc1ccc2[nH]cc(CCN3CCN(CC3)c3ccccc3-c3ccccc3F)c2c1    25.00\n",
      "4002  Clc1cccc(c1)N1CCN(CCN2CCC3(C2)C(=O)Nc2ccccc32)CC1  2687.00\n",
      "4003    CCCNC(=O)Oc1cccc2C[C@H]3N(CCC)CCc4cccc(c34)-c12    87.00\n",
      "4004  CCCN1CCc2cccc-3c2[C@H]1Cc1cccc(OC(=O)NC(C)(C)C...    96.00\n",
      "...                                                 ...      ...\n",
      "4995  COc1ccccc1N1CCN(CCN(C(=O)c2ccc(F)c(C)c2)c2cccc...     3.96\n",
      "4996                         CCCN(CCC)C1CCc2cccc(O)c2C1     3.80\n",
      "4997  COc1ccccc1N1CCN(CCCCN2C(=O)C[C@@H](NC(=O)C34CC...     9.00\n",
      "4998         COc1ccccc1N1CCN(Cc2cn3cc(C)cc(C#N)c3n2)CC1      NaN\n",
      "4999            O=C1CCc2cc(OCCCN3CCN(CC3)c3ccccn3)ccc12    19.05\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                                 SMILES        Ki\n",
      "5000        C(COc1ccccc1)NCC1COCC(O1)(c1ccccc1)c1ccccc1    0.5888\n",
      "5001       OC1(CCN(CCCC(=O)c2ccc(F)cc2)CC1)c1ccc(Cl)cc1       NaN\n",
      "5002  Clc1cccc(N2CCN(CCCCCN3C(=O)c4ccccc4S3(=O)=O)CC...   29.0000\n",
      "5003       Cl.COc1ccccc1N1CCN(CCCCCC(=O)NCc2ccccc2O)CC1   70.0000\n",
      "5004  Cc1c(oc2c(cccc2c1=O)C(=O)NCCCN1CCN(CC1)c1ccccc...    1.2000\n",
      "...                                                 ...       ...\n",
      "5836                       COc1cc(C[C@@H](C)N)c(OC)cc1I       NaN\n",
      "5837        Clc1ccc2C(=O)C(CCCCN3CCN(CC3)c3ccccn3)Cc2c1    4.0740\n",
      "5838         Clc1ccc2C(=O)C(CCCN3CCN(CC3)c3ccccn3)Cc2c1    2.3000\n",
      "5839        O=C1N(CCCCN2CCN(CC2)c2ccccc2)C(=O)c2ccccc12   10.0000\n",
      "5840                    Clc1ccc(cc1)-c1n[nH]cc1N1CCNCC1  121.0000\n",
      "\n",
      "[841 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "generator = KlekFPGenerator(n_jobs=os.cpu_count())\n",
    "data = pd.read_csv('../original_datasets/smiles/5ht1a_smiles.csv', chunksize=1000, names=['SMILES', 'Ki'])\n",
    "\n",
    "for i, chunk in enumerate(data):\n",
    "    print(chunk)\n",
    "    chunk = chunk[chunk['SMILES'].apply(could_be_valid)]\n",
    "    mols = list(map(Chem.MolFromSmiles, chunk['SMILES']))\n",
    "    fps = generator.transform(mols)\n",
    "    chunk['fps'] = list(map(sparse_to_dense, fps))\n",
    "    if i == 0:\n",
    "        chunk.to_csv('../original_datasets/klek/5ht1a_klek.csv', index=False)\n",
    "    else: # append if already exists, otherwise without else firts chunk will be written twice\n",
    "        with open('../original_datasets/klek/5ht1a_klek.csv', 'a') as f:\n",
    "            chunk.to_csv(f, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor():\n",
    "    \n",
    "    \"\"\"\n",
    "    This class loads molecular fingerprints into a DataFrame and performs clean-up on them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protein : str\n",
    "        The protein name, one of ['5ht1a', '5ht7', 'beta2', 'd2', 'h1'].\n",
    "    y_col : str, optional\n",
    "        The name of the column representing the dependent variable, default is 'Ki'.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_paths_ : dict\n",
    "        A dictionary containing the paths to the fingerprint files.\n",
    "    proteins_ : list of str\n",
    "        The list of valid protein names.\n",
    "    fingerprints_ : list of str\n",
    "        The list of valid fingerprint types.\n",
    "    protein : str\n",
    "        The protein name.\n",
    "    fingerprint : str\n",
    "        The fingerprint type.\n",
    "    path : str\n",
    "        The path to the fingerprint file.\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the loaded fingerprint data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    remove_missing()\n",
    "        Removes rows with missing values in the dependent variable column.\n",
    "    remove_duplicates()\n",
    "        Removes duplicate rows in the DataFrame.\n",
    "    remove_redundant()\n",
    "        Removes redundant columns in the DataFrame.\n",
    "    convert_data()\n",
    "        Converts the data types of the columns in the DataFrame.\n",
    "    add_classification(threshold)\n",
    "        Adds a Class column to the DataFrame based on the threshold parameter.\n",
    "    write_cleaned()\n",
    "        Writes the cleaned DataFrame to a csv file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, protein, y_col='Ki'):\n",
    "        sys.path.append('..')\n",
    "        self.data_paths = {\n",
    "    '5ht1a': '../original_datasets/klek/5ht1a_klek.csv',\n",
    "    '5ht7': '../original_datasets/klek/5ht7_klek.csv',\n",
    "    'beta2': '../original_datasets/klek/beta2_klek.csv',\n",
    "    'd2': '../original_datasets/klek/d2_klek.csv',\n",
    "    'h1': '../original_datasets/klek/h1_klek.csv'\n",
    "    }\n",
    "            \n",
    "        self.proteins_ = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']\n",
    "        self.y_col = y_col\n",
    "        self.missing = None\n",
    "        self.duplicated = None\n",
    "        self.redundant = None\n",
    "        \n",
    "        self.protein = protein\n",
    "        self.path = self.data_paths[protein]\n",
    "        \n",
    "        self.activities = {\n",
    "    '5ht1a': 54,\n",
    "    '5ht7': 89,\n",
    "    'beta2': 270,\n",
    "    'd2': 240.1,\n",
    "    'h1': 501\n",
    "    }\n",
    "        \n",
    "        self.threshold = self.activities[self.protein]\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.df = pd.read_csv(self.path)\n",
    "        self.df[self.y_col] = self.df[self.y_col].astype('float')\n",
    "        print(f\"Loaded data for {self.protein} protein\")\n",
    "        \n",
    "        \n",
    "    def remove_missing(self):\n",
    "        print(f'The initial size of dataset: {len(self.df)}')\n",
    "        missing = self.df[self.y_col].isnull()\n",
    "        zero_or_neg = self.df[self.y_col] <= 0\n",
    "        to_remove = pd.Series([a or b for a, b in zip(missing,zero_or_neg)])\n",
    "        print(f'The percent of rows with missing {self.y_col} values: {to_remove.sum()/len(self.df)*100:.2f} %')\n",
    "        self.df = self.df[~to_remove]\n",
    "        print(f'New size of the dataset: {len(self.df)}')\n",
    "        self.missing = int(to_remove.sum())\n",
    "        \n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        print(f'The initial size of dataset: {len(self.df)}')\n",
    "        duplicates = self.df.duplicated(keep = 'first')\n",
    "        print(f'The percent of duplicated rows: {duplicates.sum()/len(self.df)*100:.2f} %')\n",
    "        self.df = self.df[~duplicates]\n",
    "        print(f'New size of the dataset: {len(self.df)}')\n",
    "        self.duplicated = int(duplicates.sum())\n",
    "        \n",
    "        \n",
    "    def add_classification(self):\n",
    "        classes = [1 if x < 100 else 0 for x in self.df[self.y_col]]\n",
    "        self.df.insert(1, \"Class\", classes)\n",
    "        print(f'The percent of compounds classified as active is {self.df[\"Class\"].sum()/len(self.df)*100:.2f} %')\n",
    "        \n",
    "                \n",
    "    def write_cleaned(self):\n",
    "        write_path = '../original_datasets/klek_clean/' + self.protein + '_klek_100nM.csv'\n",
    "        self.df.to_csv(path_or_buf=write_path, sep=',', index=False)\n",
    "        print(f'Cleaned file saved at {write_path}')\n",
    "    \n",
    "    \n",
    "    def return_parameters(self): # zwraca listę list dotyczącą ile czego brakowało/usunięto w kolejności wczytania do klasy\n",
    "        parameters = []\n",
    "        parameters.append(self.missing)\n",
    "        parameters.append(self.duplicated)\n",
    "        parameters.append(self.redundant)\n",
    "        return parameters\n",
    "    \n",
    "    def write_parquet(self):\n",
    "        path = '..' + self.path.strip('.csv') + '_balanced.parquet'\n",
    "        print(path)\n",
    "        self.df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = ['5ht1a','5ht7','beta2','d2','h1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 5ht1a protein\n",
      "The initial size of dataset: 5840\n",
      "The percent of rows with missing Ki values: 3.78 %\n",
      "New size of the dataset: 5619\n",
      "The initial size of dataset: 5619\n",
      "The percent of duplicated rows: 6.57 %\n",
      "New size of the dataset: 5250\n",
      "The percent of compounds classified as active is 57.96 %\n",
      "Cleaned file saved at ../original_datasets/klek_clean/5ht1a_klek_100nM.csv\n",
      "Loaded data for 5ht7 protein\n",
      "The initial size of dataset: 3262\n",
      "The percent of rows with missing Ki values: 3.86 %\n",
      "New size of the dataset: 3136\n",
      "The initial size of dataset: 3136\n",
      "The percent of duplicated rows: 5.52 %\n",
      "New size of the dataset: 2963\n",
      "The percent of compounds classified as active is 51.50 %\n",
      "Cleaned file saved at ../original_datasets/klek_clean/5ht7_klek_100nM.csv\n",
      "Loaded data for beta2 protein\n",
      "The initial size of dataset: 1660\n",
      "The percent of rows with missing Ki values: 51.51 %\n",
      "New size of the dataset: 805\n",
      "The initial size of dataset: 805\n",
      "The percent of duplicated rows: 2.86 %\n",
      "New size of the dataset: 782\n",
      "The percent of compounds classified as active is 42.33 %\n",
      "Cleaned file saved at ../original_datasets/klek_clean/beta2_klek_100nM.csv\n",
      "Loaded data for d2 protein\n",
      "The initial size of dataset: 11816\n",
      "The percent of rows with missing Ki values: 9.09 %\n",
      "New size of the dataset: 10742\n",
      "The initial size of dataset: 10742\n",
      "The percent of duplicated rows: 5.32 %\n",
      "New size of the dataset: 10170\n",
      "The percent of compounds classified as active is 36.51 %\n",
      "Cleaned file saved at ../original_datasets/klek_clean/d2_klek_100nM.csv\n",
      "Loaded data for h1 protein\n",
      "The initial size of dataset: 2591\n",
      "The percent of rows with missing Ki values: 32.88 %\n",
      "New size of the dataset: 1739\n",
      "The initial size of dataset: 1739\n",
      "The percent of duplicated rows: 2.76 %\n",
      "New size of the dataset: 1691\n",
      "The percent of compounds classified as active is 37.91 %\n",
      "Cleaned file saved at ../original_datasets/klek_clean/h1_klek_100nM.csv\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    data = DataProcessor(protein)\n",
    "    data.load_data()\n",
    "    data.remove_missing()\n",
    "    data.remove_duplicates()\n",
    "    data.add_classification()\n",
    "    data.write_cleaned()\n",
    "    #data.write_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = ['5ht1a','5ht7','beta2','d2','h1']\n",
    "\n",
    "read_paths = [f'../original_datasets/klek_clean/{x}_klek_balanced.csv' for x in proteins]\n",
    "write_paths = [f'../original_datasets/parquet_clean/{x}_klek_balanced.parquet' for x in proteins]\n",
    "\n",
    "def csv_to_parquet(read_path, write_path):\n",
    "    data = pd.read_csv(read_path, sep=',')\n",
    "    data.to_parquet(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../original_datasets/klek_clean/5ht1a_klek_balanced.csv ../original_datasets/parquet_clean/5ht1a_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/5ht7_klek_balanced.csv ../original_datasets/parquet_clean/5ht7_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/beta2_klek_balanced.csv ../original_datasets/parquet_clean/beta2_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/d2_klek_balanced.csv ../original_datasets/parquet_clean/d2_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/h1_klek_balanced.csv ../original_datasets/parquet_clean/h1_klek_balanced.parquet\n"
     ]
    }
   ],
   "source": [
    "for read_path, write_path in zip(read_paths, write_paths):\n",
    "    print(read_path, write_path)\n",
    "    csv_to_parquet(read_path, write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
