{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rdkit\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c84e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor():\n",
    "    \n",
    "    \"\"\"\n",
    "    This class loads molecular fingerprints for drugs acting on 5 different proteins into a DataFrame and performs \n",
    "    clean-up on them. The cleaned datasets can be written as csv files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protein : str\n",
    "        The protein name, one of ['5ht1a', '5ht7', 'beta2', 'd2', 'h1'].\n",
    "    fingerprint : str\n",
    "        The fingerprint type, one of ['Klek', 'Sub', 'MACCS'].\n",
    "    y_col : str, optional\n",
    "        The name of the column representing the dependent variable, default is 'Ki'.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_paths_ : dict\n",
    "        A dictionary containing the paths to the fingerprint files.\n",
    "    proteins_ : list of str\n",
    "        The list of valid protein names.\n",
    "    fingerprints_ : list of str\n",
    "        The list of valid fingerprint types.\n",
    "    protein : str\n",
    "        The protein name.\n",
    "    fingerprint : str\n",
    "        The fingerprint type.\n",
    "    path : str\n",
    "        The path to the fingerprint file.\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the loaded fingerprint data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    remove_missing()\n",
    "        Removes rows with missing values in the dependent variable column.\n",
    "    remove_duplicates()\n",
    "        Removes duplicate rows in the DataFrame.\n",
    "    remove_redundant()\n",
    "        Removes redundant columns in the DataFrame.\n",
    "    convert_data()\n",
    "        Converts the data types of the columns in the DataFrame.\n",
    "    add_classification(threshold)\n",
    "        Adds a Class column to the DataFrame based on the threshold parameter.\n",
    "    write_cleaned()\n",
    "        Writes the cleaned DataFrame to a csv file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, protein, fingerprint, y_col='Ki'):\n",
    "        sys.path.append('..')\n",
    "        self.data_paths_ = {\n",
    "    '5ht1a_Klek' : './datasets/5ht1a_KlekFP.csv',\n",
    "    '5ht1a_MACCS' : './datasets/5ht1a_MACCSFP.csv',\n",
    "    '5ht1a_Sub' : './datasets/5ht1a_SubFP.csv',\n",
    "    '5ht7_Klek' : './datasets/5ht7_KlekFP.csv',\n",
    "    '5ht7_MACCS' : './datasets/5ht7_MACCSFP.csv',\n",
    "    '5ht7_Sub' : './datasets/5ht7_SubFP.csv',\n",
    "    'beta2_Klek' : './datasets/beta2_KlekFP.csv',\n",
    "    'beta2_MACCS' : './datasets/beta2_MACCSFP.csv',\n",
    "    'beta2_Sub' : './datasets/beta2_SubFP.csv',\n",
    "    'd2_Klek' : './datasets/d2_KlekFP.csv',\n",
    "    'd2_MACCS' : './datasets/d2_MACCSFP.csv',\n",
    "    'd2_Sub' : './datasets/d2_SubFP.csv',\n",
    "    'h1_Klek' : './datasets/h1_KlekFP.csv',\n",
    "    'h1_MACCS' : './datasets/h1_MACCSFP.csv',\n",
    "    'h1_Sub' : './datasets/h1_SubFP.csv'\n",
    "    }\n",
    "            \n",
    "        self.proteins_ = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']\n",
    "        self.fingerprints_ = ['Klek', 'Sub', 'MACCS']\n",
    "        self.y_col = y_col\n",
    "        \n",
    "        self.protein = protein\n",
    "        self.fingerprint = fingerprint\n",
    "        self.path = self.protein + '_' + self.fingerprint\n",
    "        if self.path in self.data_paths_.keys():\n",
    "            self.df = pd.read_csv(self.data_paths_[self.path])\n",
    "            print(f'{self.fingerprint} FP for protein {self.protein} loaded')\n",
    "        else:\n",
    "            self.df = None\n",
    "            print(\"Protein and fingerprint combination not found\")\n",
    "        \n",
    "        \n",
    "    def remove_missing(self):\n",
    "        print(f'The initial size of dataset: {len(self.df)}')\n",
    "        missing = self.df[self.y_col].isnull()\n",
    "        print(f'The percent of rows with missing {self.y_col} values: {missing.sum()/len(self.df)*100:.2f} %')\n",
    "        self.df = self.df[~missing]\n",
    "        print(f'New size of the dataset: {len(self.df)}')\n",
    "        \n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        print(f'The initial size of dataset: {len(self.df)}')\n",
    "        duplicates = self.df.duplicated(keep = 'first')\n",
    "        print(f'The percent of duplicated rows: {duplicates.sum()/len(self.df)*100:.2f} %')\n",
    "        self.df = self.df[~duplicates]\n",
    "        print(f'New size of the dataset: {len(self.df)}')\n",
    "        \n",
    "        \n",
    "    def remove_redundant(self):\n",
    "        col1 = len(self.df.columns)\n",
    "        selection = [True if sum > 0 else False for sum in self.df.sum(axis=0)]\n",
    "        self.df = self.df.loc[:, selection]\n",
    "        col2 = len(self.df.columns)\n",
    "        print(f'There were {col1-col2} redundant columns in the dataset.')\n",
    "        \n",
    "        \n",
    "    def convert_data(self):\n",
    "        self.df[self.y_col] = self.df[self.y_col].astype(float)\n",
    "        columns = self.df.columns[1:]\n",
    "        self.df[columns] = self.df[columns].astype(int)\n",
    "        \n",
    "        \n",
    "    def add_classification(self, threshold = 100):\n",
    "        classes = [1 if x < threshold else 0 for x in self.df[self.y_col]]\n",
    "        self.df.insert(1, \"Class\", classes)\n",
    "        print(f'The percent of compounds classified as active is {self.df[\"Class\"].sum()/len(self.df)*100:.2f} %')\n",
    "        \n",
    "                \n",
    "    def write_cleaned(self):\n",
    "        write_path = './cleaned_datasets/' + self.path + '_clean.csv'\n",
    "        self.df.to_csv(path_or_buf=write_path, sep=',', index=False)\n",
    "        print(f'Cleaned file saved at {write_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec6953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACCS FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.78 %\n",
      "New size of the dataset: 5630\n",
      "The initial size of dataset: 5630\n",
      "The percent of duplicated rows: 8.33 %\n",
      "New size of the dataset: 5161\n",
      "There were 18 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.19 %\n"
     ]
    }
   ],
   "source": [
    "data = DataProcessor(protein='5ht1a', fingerprint='MACCS')\n",
    "data.remove_missing()\n",
    "data.remove_duplicates()\n",
    "data.remove_redundant()\n",
    "data.add_classification()\n",
    "data.convert_data()\n",
    "\n",
    "# data.write_cleaned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c71d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klek FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.78 %\n",
      "New size of the dataset: 5630\n",
      "The initial size of dataset: 5630\n",
      "The percent of duplicated rows: 7.66 %\n",
      "New size of the dataset: 5199\n",
      "There were 3263 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.11 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht1a_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.78 %\n",
      "New size of the dataset: 5630\n",
      "The initial size of dataset: 5630\n",
      "The percent of duplicated rows: 10.23 %\n",
      "New size of the dataset: 5054\n",
      "There were 190 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.61 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht1a_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.78 %\n",
      "New size of the dataset: 5630\n",
      "The initial size of dataset: 5630\n",
      "The percent of duplicated rows: 8.33 %\n",
      "New size of the dataset: 5161\n",
      "There were 18 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.19 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht1a_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 6.18 %\n",
      "New size of the dataset: 2945\n",
      "There were 3508 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 51.34 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht7_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 8.89 %\n",
      "New size of the dataset: 2860\n",
      "There were 204 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 51.89 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht7_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 7.45 %\n",
      "New size of the dataset: 2905\n",
      "There were 21 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 51.81 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht7_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 3.70 %\n",
      "New size of the dataset: 781\n",
      "There were 3800 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 41.87 %\n",
      "Cleaned file saved at ./cleaned_datasets/beta2_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 6.29 %\n",
      "New size of the dataset: 760\n",
      "There were 199 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 42.37 %\n",
      "Cleaned file saved at ./cleaned_datasets/beta2_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 4.44 %\n",
      "New size of the dataset: 775\n",
      "There were 16 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 42.19 %\n",
      "Cleaned file saved at ./cleaned_datasets/beta2_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.06 %\n",
      "New size of the dataset: 10750\n",
      "The initial size of dataset: 10750\n",
      "The percent of duplicated rows: 6.08 %\n",
      "New size of the dataset: 10096\n",
      "There were 3060 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 36.61 %\n",
      "Cleaned file saved at ./cleaned_datasets/d2_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.06 %\n",
      "New size of the dataset: 10750\n",
      "The initial size of dataset: 10750\n",
      "The percent of duplicated rows: 10.49 %\n",
      "New size of the dataset: 9622\n",
      "There were 169 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 37.75 %\n",
      "Cleaned file saved at ./cleaned_datasets/d2_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.06 %\n",
      "New size of the dataset: 10750\n",
      "The initial size of dataset: 10750\n",
      "The percent of duplicated rows: 7.57 %\n",
      "New size of the dataset: 9936\n",
      "There were 14 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 36.96 %\n",
      "Cleaned file saved at ./cleaned_datasets/d2_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 3.50 %\n",
      "New size of the dataset: 1680\n",
      "There were 3581 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 38.21 %\n",
      "Cleaned file saved at ./cleaned_datasets/h1_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 9.76 %\n",
      "New size of the dataset: 1571\n",
      "There were 205 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 39.34 %\n",
      "Cleaned file saved at ./cleaned_datasets/h1_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 5.40 %\n",
      "New size of the dataset: 1647\n",
      "There were 18 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 38.43 %\n",
      "Cleaned file saved at ./cleaned_datasets/h1_MACCS_clean.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proteins = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']\n",
    "keys = ['Klek', 'Sub', 'MACCS']\n",
    "\n",
    "for protein in proteins:\n",
    "        for key in keys:\n",
    "            data = DataProcessor(protein=protein, fingerprint=key)\n",
    "            data.remove_missing()\n",
    "            data.remove_duplicates()\n",
    "            data.remove_redundant()\n",
    "            data.add_classification()\n",
    "            data.convert_data()\n",
    "            data.write_cleaned()\n",
    "            print('\\n')\n",
    "            del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
