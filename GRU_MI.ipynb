{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef6f3f5",
   "metadata": {
    "id": "6ef6f3f5"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from gru import dataset, example_printer\n",
    "from gru.gru_v2 import EncoderNet, DecoderNet, EncoderDecoder\n",
    "from gru.cce import CCE\n",
    "import torch\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from selfies_tools import SELFIESVectorizer, determine_alphabet\n",
    "import random\n",
    "import selfies as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "N3BCODbh2PhC",
   "metadata": {
    "id": "N3BCODbh2PhC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8b28d1",
   "metadata": {
    "id": "9b8b28d1"
   },
   "outputs": [],
   "source": [
    "x_path = './GRU_data/combined_klek.parquet'\n",
    "y_path = './GRU_data/combined_selfies.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a846df51",
   "metadata": {
    "id": "a846df51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhubertrybka1\u001b[0m (\u001b[33mmldd23\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "# weights and biases\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16dfcb1",
   "metadata": {
    "id": "f16dfcb1"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b30b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = determine_alphabet(y_path) \n",
    "vectorizer = SELFIESVectorizer(alphabet, pad_to_len = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69823bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 402863\n",
      "Train size: 362576\n",
      "Test size: 40287\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.GRUDataset(x_path, y_path, vectorizer)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4f014e",
   "metadata": {
    "id": "da4f014e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9e02f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.95 GiB total capacity; 1.28 GiB already allocated; 10.62 MiB free; 1.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m x\u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m y\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m out[:,\u001b[38;5;241m1\u001b[39m,:]\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/github/mldd23_project1/gru/gru_v2.py:79\u001b[0m, in \u001b[0;36mEncoderDecoder.forward\u001b[0;34m(self, x, y, teacher_forcing)\u001b[0m\n\u001b[1;32m     77\u001b[0m decoded \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m128\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)) \u001b[38;5;66;03m# [batch_size, 1, hidden_size] -> [batch_size, 1, 42]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     decoded\u001b[38;5;241m.\u001b[39mappend(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/github/mldd23_project1/gru/gru_v2.py:43\u001b[0m, in \u001b[0;36mDecoderNet.forward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m#x.shape = [batch_size, selfie_len, encoding_size] = [64, 128, 256]\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     out, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m#out.shape = [batch_size, selfie_len, hidden_size] = [64, 128, 256]\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#h.shape = [num_layers, batch_size, hidden_size] = [1, 64, 256]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out, h\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mldd23/lib/python3.9/site-packages/torch/nn/modules/rnn.py:955\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    959\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.95 GiB total capacity; 1.28 GiB already allocated; 10.62 MiB free; 1.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "x= x.to(device)\n",
    "y= y.to(device)\n",
    "\n",
    "out = model(x, y, teacher_forcing=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39daf",
   "metadata": {
    "id": "02f39daf"
   },
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f598e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "encoding_size = 256\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "learn_rate = 0.00025\n",
    "dropout = 0 # dropout must be equal 0 if num_layers = 1\n",
    "\n",
    "# Init model\n",
    "model = EncoderDecoder(\n",
    "    fp_size=4860,\n",
    "    encoding_size=encoding_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f697df",
   "metadata": {
    "id": "c3f697df"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b00cca",
   "metadata": {
    "id": "f7b00cca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, test_loader, vectorizer, device):\n",
    "\n",
    "    EPOCHS = 20\n",
    "\n",
    "    # Define dataframe for training progess display\n",
    "    epochs_range = range(1,EPOCHS+1)\n",
    "    metrics = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss']);\n",
    "    metrics['epoch'] = epochs_range\n",
    "    \n",
    "    # Init example printer\n",
    "    printer = example_printer.ExamplePrinter(test_loader, num_examples=5)\n",
    "\n",
    "    # Define pyplot for plotting metrics\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(7, 3), layout=\"constrained\")\n",
    "    dh = display(fig, display_id=True)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    criterion = CCE()\n",
    "\n",
    "    # wandb config and init\n",
    "    config = dict()\n",
    "    config['learning rate'] = learn_rate\n",
    "    config['encoding size'] = model.encoding_size\n",
    "    config['criterion'] = criterion\n",
    "    config['optimizer'] = optimizer\n",
    "    config['num epochs'] = EPOCHS\n",
    "    config['Trainable parameters'] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    config['hidden size'] = model.hidden_size\n",
    "    config['Number of layers'] = num_layers\n",
    "    config['Dropout'] = model.decoder.dropout\n",
    "    config['Batch size'] = batch_size\n",
    "    wandb.init(project=\"encoded-token-concat\", config=config)\n",
    "\n",
    "    print(\"Starting Training of GRU\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    samples = []\n",
    "    \n",
    "    # Start training loop\n",
    "    for epoch in epochs_range:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for batch_idx, (X,y) in enumerate(tqdm(train_loader)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X, y, teacher_forcing=True).to(device)\n",
    "            loss = criterion(y, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # calculate loss and log to wandb\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        val_loss = evaluate(model, test_loader)\n",
    "        metrics_dict = {'epoch': epoch,\n",
    "                        'train_loss': avg_loss,\n",
    "                        'val_loss': val_loss}\n",
    "        wandb.log(metrics_dict)\n",
    "\n",
    "        # Update metrics df\n",
    "        metrics.loc[len(metrics)] = metrics_dict\n",
    "\n",
    "        # Display metrics\n",
    "        ax[0].clear()\n",
    "        ax[0].plot(metrics.epoch, metrics.train_loss)\n",
    "        ax[0].set_title('training loss')\n",
    "        ax[0].set_xlabel('epoch')\n",
    "        ax[0].set_ylabel('CrossEntropy')\n",
    "        ax[1].clear()\n",
    "        ax[1].plot(metrics.epoch, metrics.val_loss)\n",
    "        ax[1].set_title('validation loss')\n",
    "        ax[1].set_xlabel('epoch')\n",
    "        ax[1].set_ylabel('CrossEntropy')\n",
    "        dh.update(fig)\n",
    "        \n",
    "        new_samples = printer(model)\n",
    "        samples.append(new_samples)\n",
    "        \n",
    "    plt.close()\n",
    "    wandb.finish()\n",
    "    return model, samples\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    criterion = CCE()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (X, y) in enumerate(test_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(X, y, teacher_forcing=False).to(device)\n",
    "        loss = criterion(y, output)\n",
    "        epoch_loss += loss.item()\n",
    "    avg_loss = epoch_loss / len(test_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874519b",
   "metadata": {
    "id": "c874519b"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839d044",
   "metadata": {
    "id": "0839d044"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhubertrybka1\u001b[0m (\u001b[33mmldd23\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hubert/github/mldd23_project1/wandb/run-20230618_131214-s4pj40fp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mldd23/encoded-token-concat/runs/s4pj40fp' target=\"_blank\">fancy-donkey-20</a></strong> to <a href='https://wandb.ai/mldd23/encoded-token-concat' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mldd23/encoded-token-concat' target=\"_blank\">https://wandb.ai/mldd23/encoded-token-concat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mldd23/encoded-token-concat/runs/s4pj40fp' target=\"_blank\">https://wandb.ai/mldd23/encoded-token-concat/runs/s4pj40fp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU\n",
      "Device: cuda\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 708/708 [13:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted SELFIE:\n",
      "[C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1] \n",
      "\n",
      "True SELFIE:\n",
      "[C][O][C][C][N][C][C][N][Branch2][Ring1][#Branch1][C][C][C][Branch1][C][C][=N][N][Branch1][=Branch2][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=Ring1][N][Cl][C][C][Ring2][Ring1][Ring2][=O]\n",
      "------------------------------------------------------------\n",
      "Predicted SELFIE:\n",
      "[C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1] \n",
      "\n",
      "True SELFIE:\n",
      "[C][C@H1][Branch2][Ring1][Ring1][S][C][=N][N][=C][Branch1][Branch2][C][=C][C][=C][S][Ring1][Branch1][N][Ring1][#Branch2][N][C][=Branch1][C][=O][N][C][=C][C][=C][C][=C][C][=C][C][=C][Ring1][#Branch2][Ring1][=Branch1]\n",
      "------------------------------------------------------------\n",
      "Predicted SELFIE:\n",
      "[C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][Ring1][Ring1][Ring1][Ring1] \n",
      "\n",
      "True SELFIE:\n",
      "[C][C][=C][Branch1][C][Cl][N][=C][Branch1][=N][N][C@H1][C][C][C@H1][Branch1][C][N][C][C][Ring1][#Branch1][C][=Branch1][C][=O][N][Ring1][S][C][C][=Branch1][C][=O][N][C][=C][C][=C][C][Branch1][C][N][=C][Ring1][#Branch1][O][=C][Branch1][C][O][C][Branch1][C][F][Branch1][C][F][F]\n",
      "------------------------------------------------------------\n",
      "Predicted SELFIE:\n",
      "[C][C][C][=C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1][Ring1] \n",
      "\n",
      "True SELFIE:\n",
      "[C][O][C][=Branch1][C][=O][N][C][=C][C][=C][C][=Branch1][Ring2][=C][Ring1][=Branch1][N][Branch1][#C][C][=Branch1][C][=O][C][C][N][C][C][O][C][C][Ring1][=Branch1][C][=C][C][=C][C][=C][Ring1][=Branch1][C][C][Ring2][Ring1][=Branch1]\n",
      "------------------------------------------------------------\n",
      "Predicted SELFIE:\n",
      "[C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][C][Ring1][Ring1][Ring1][Ring1] \n",
      "\n",
      "True SELFIE:\n",
      "[O][=C][Branch1][=N][N][C][C][=C][NH1][C][=Branch1][C][=O][C][=Ring1][#Branch1][C][=C][C][=C][Branch1][=Branch2][C][Branch1][C][F][Branch1][C][F][F][C][=C][Ring1][#Branch2][O][C][=C][C][=C][Branch1][=Branch2][C][Branch1][C][F][Branch1][C][F][F][N][=C][Ring1][#Branch2]\n",
      "------------------------------------------------------------\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▌                                  | 114/708 [02:39<11:36,  1.17s/it]"
     ]
    }
   ],
   "source": [
    "model, samples = train(model, train_loader, test_loader, vectorizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8614d46",
   "metadata": {
    "id": "f8614d46"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), './GRU_data/params/w-teacher-0')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
