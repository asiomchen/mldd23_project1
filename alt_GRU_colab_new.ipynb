{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef6f3f5",
   "metadata": {
    "id": "6ef6f3f5"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "N3BCODbh2PhC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3BCODbh2PhC",
    "outputId": "49856abc-e54c-486b-a844-9ab9b722d526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# set colab/local and cpu/cuda\n",
    "COLAB = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8b28d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b8b28d1",
    "outputId": "a5ebf666-fd97-4fa0-a3ff-728714b4e60f"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # iload data from google drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "    !pip install selfies\n",
    "    !pip install wandb\n",
    "\n",
    "    x_path = '/content/drive/My Drive/GRU_data/250k_klek.csv'\n",
    "    y_path = '/content/drive/My Drive/GRU_data/250k_selfies.csv'\n",
    "else:\n",
    "    # load data from local directory\n",
    "    x_path = './GRU_data/250k_klek.csv'\n",
    "    y_path = './GRU_data/250k_selfies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a846df51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a846df51",
    "outputId": "93eff75d-8119-4d95-8edc-a502493f6b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhubertrybka1\u001b[0m (\u001b[33mmldd23\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "# weights and biases\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16dfcb1",
   "metadata": {
    "id": "f16dfcb1"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fbcdb",
   "metadata": {
    "id": "8a3fbcdb"
   },
   "outputs": [],
   "source": [
    "# alphabet of tokens for output\n",
    "\n",
    "import selfies as sf\n",
    "data = pd.read_csv(y_path)\n",
    "alphabet = sf.get_alphabet_from_selfies(data.selfies)\n",
    "alphabet.add(\"[start]\")\n",
    "alphabet.add(\"[end]\")\n",
    "alphabet.add(\"[nop]\") # [nop] is a special padding symbol\n",
    "alphabet = list(sorted(alphabet))\n",
    "#pad_to_len = max(sf.len_selfies(s) for s in data.selfies) + 10\n",
    "pad_to_len = 128 # for simplicities' sake\n",
    "symbol_to_idx = {s: i for i, s in enumerate(alphabet)}\n",
    "idx2char = {i: s for i, s in enumerate(alphabet)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a6d94",
   "metadata": {
    "id": "f55a6d94"
   },
   "outputs": [],
   "source": [
    "class SELFIESVectorizer:\n",
    "    def __init__(self, alphabet, pad_to_len=None):\n",
    "        self.alphabet = alphabet\n",
    "        self.char2idx = {s: i for i, s in enumerate(alphabet)}\n",
    "        self.idx2char = {i: s for i, s in enumerate(alphabet)}\n",
    "        self.pad_to_len = pad_to_len\n",
    "    def vectorize(self, selfie, no_special=False):\n",
    "        ''' Vectorize a list of SMILES strings to a numpy array of shape (len(smiles), embed, len(charset))'''\n",
    "        if no_special:\n",
    "            splited = self.split_selfi(selfie)\n",
    "        elif self.pad_to_len is None:\n",
    "            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]']\n",
    "        else:\n",
    "            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]'] + ['[nop]'] * (self.pad_to_len - len(self.split_selfi(selfie)) - 2)\n",
    "        X = np.zeros((len(splited), len(self.alphabet)))\n",
    "        for i in range(len(splited)):\n",
    "            X[i, self.char2idx[splited[i]]] = 1\n",
    "        return X\n",
    "    def devectorize(self, ohe, remove_special=False):\n",
    "        ''' Devectorize a numpy array of shape (len(smiles), embed, len(charset)) to a list of SMILES strings'''\n",
    "        selfie_str = ''\n",
    "        for j in range(ohe.shape[0]):\n",
    "            idx = np.argmax(ohe[j, :])\n",
    "            if remove_special and (self.idx2char[idx] == '[start]' or self.idx2char[idx] == '[end]'):\n",
    "                continue\n",
    "            selfie_str += self.idx2char[idx]\n",
    "        return selfie_str\n",
    "    def idxize(self, selfie, no_special=False):\n",
    "        if no_special:\n",
    "            splited = self.split_selfi(selfie)\n",
    "        else:\n",
    "            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]'] + ['[nop]'] * (self.pad_to_len - len(self.split_selfi(selfie)) - 2)\n",
    "        return np.array([self.char2idx[s] for s in splited])\n",
    "    def deidxize(self, idx):\n",
    "        return \"\".join([self.idx2char[i] for i in idx])\n",
    "    def split_selfi(self, selfie):\n",
    "        pattern = r'(\\[[^\\[\\]]*\\])'\n",
    "        return re.findall(pattern, selfie)\n",
    "vectorizer = SELFIESVectorizer(alphabet, pad_to_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538d564",
   "metadata": {
    "id": "6538d564"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GRUDatasetv2(Dataset):\n",
    "    def __init__(self, smiles_fp, selfies, vectorizer):\n",
    "        self.smiles_fp = pd.read_csv(smiles_fp)\n",
    "        self.selfies = pd.read_csv(selfies)\n",
    "        self.selfies= self.prepare_y(self.selfies)\n",
    "        self.vectorizer = vectorizer\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_fp)\n",
    "    def __getitem__(self, idx):\n",
    "        raw_selfie = self.selfies[idx][0]\n",
    "        vectorized_selfie = self.vectorizer.vectorize(raw_selfie)\n",
    "        raw_X = self.smiles_fp.fps[idx]\n",
    "        X = np.array(eval(raw_X), dtype=int)\n",
    "        X_reconstructed = self.reconstruct_fp(X)\n",
    "        return torch.from_numpy(X_reconstructed).float(), torch.from_numpy(vectorized_selfie).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_X(smiles_fp):\n",
    "        fps = smiles_fp.fps.apply(eval).apply(lambda x: np.array(x, dtype=int))\n",
    "        return fps\n",
    "    @staticmethod\n",
    "    def prepare_y(selfies):\n",
    "        return selfies.values\n",
    "        \n",
    "    @staticmethod\n",
    "    def reconstruct_fp(fp, length=4860):\n",
    "        fp_rec = np.zeros(length)\n",
    "        fp_rec[fp] = 1\n",
    "        return fp_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062168b4",
   "metadata": {
    "id": "062168b4"
   },
   "outputs": [],
   "source": [
    "dataset = GRUDatasetv2(x_path, y_path, vectorizer)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16a986",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a16a986",
    "outputId": "20eb3f72-4d80-472e-dcc8-33e51f6caeec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 183879\n",
      "Train size: 165491\n",
      "Test size: 18388\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f014e",
   "metadata": {
    "id": "da4f014e"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39daf",
   "metadata": {
    "id": "02f39daf"
   },
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8248e95c",
   "metadata": {
    "id": "8248e95c"
   },
   "outputs": [],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self, fp_size, encoding_size):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(fp_size, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, encoding_size)\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.relu(self.fc4(out))\n",
    "        #out.shape = [batch_size, 256]\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super(DecoderNet, self).__init__()\n",
    "        \n",
    "        # GRU parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # output token count\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # pytorch.nn\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                          dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        #x.shape = [batch_size, selfie_len, encoding_size] = [64, 128, 256]\n",
    "        out, h = self.gru(x, h)\n",
    "        #out.shape = [batch_size, selfie_len, hidden_size] = [64, 128, 256]\n",
    "        #h.shape = [num_layers, batch_size, hidden_size] = [1, 64, 256]\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11abf2",
   "metadata": {
    "id": "ea11abf2"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, fp_size=4860, encoding_size=256, hidden_size=256, num_layers=2, output_size=42, dropout=0.2):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = EncoderNet(fp_size, encoding_size)\n",
    "        self.decoder = DecoderNet(encoding_size, hidden_size, num_layers, output_size, dropout)\n",
    "        self.encoding_size = encoding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #pytorch.nn\n",
    "        self.fc = nn.Linear(hidden_size, 42)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax2d = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.decoder.init_hidden(batch_size=x.shape[0]).to(device)\n",
    "        encoded = self.encoder(x)\n",
    "        x = encoded.unsqueeze(1)\n",
    "        decoded = []\n",
    "        for n in range(128):\n",
    "            out, hidden = self.decoder(x, hidden)\n",
    "            x = out\n",
    "            out = self.relu(self.fc(out))\n",
    "            decoded.append(out)\n",
    "        out_cat = torch.cat(decoded, dim=1)\n",
    "        out_cat = self.softmax2d(out_cat)\n",
    "        return out_cat # shape [batch_size, selfie_len, alphabet_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0cf5ff",
   "metadata": {
    "id": "8e0cf5ff"
   },
   "source": [
    "#  NN Debugging section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0132236",
   "metadata": {
    "id": "c0132236"
   },
   "outputs": [],
   "source": [
    "# define encoder and decoder\n",
    "\n",
    "encoder = EncoderNet(fp_size=4860)\n",
    "decoder = DecoderNet(input_size=256, hidden_size=256, num_layers=2, output_size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b4559",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a49b4559",
    "outputId": "ac44a3e1-887d-4031-ffd5-2d93d3539a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([256, 1, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128, 42])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test batch, encode and reshape\n",
    "\n",
    "test_src = next(iter(train_loader))[0]\n",
    "test_trg = next(iter(train_loader))[1]\n",
    "encoded = encoder(test_src)\n",
    "encoded = encoded.unsqueeze(1)\n",
    "print(f'Encoded shape: {encoded.shape}')\n",
    "test_trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2893d40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2893d40",
    "outputId": "d55edb6c-28d8-4882-90e4-155dd73e13a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src shape: torch.Size([256, 4860])\n",
      "Trg shape: torch.Size([256, 128, 42])\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder()\n",
    "model = model.to(device)\n",
    "test_src = next(iter(train_loader))[0].to(device)\n",
    "test_trg = next(iter(train_loader))[1].to(device)\n",
    "print(f'Src shape: {test_src.shape}')\n",
    "print(f'Trg shape: {test_trg.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ead312",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66ead312",
    "outputId": "1c363791-10c0-4c80-9c66-f3d830106dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([256, 128, 42])\n",
      "Outputs shape after argmax: (256, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0235, 0.0236, 0.0235,  ..., 0.0249, 0.0249, 0.0235],\n",
       "        [0.0235, 0.0237, 0.0235,  ..., 0.0248, 0.0249, 0.0235],\n",
       "        [0.0235, 0.0239, 0.0236,  ..., 0.0247, 0.0250, 0.0235],\n",
       "        ...,\n",
       "        [0.0235, 0.0244, 0.0239,  ..., 0.0242, 0.0253, 0.0235],\n",
       "        [0.0235, 0.0244, 0.0239,  ..., 0.0242, 0.0253, 0.0235],\n",
       "        [0.0235, 0.0244, 0.0239,  ..., 0.0242, 0.0253, 0.0235]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(test_src)\n",
    "print(f'Outputs shape: {outputs.shape}')\n",
    "\n",
    "output = torch.argmax(outputs, dim=2)\n",
    "output = output.cpu().detach().numpy()\n",
    "print(f'Outputs shape after argmax: {output.shape}')\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a1163",
   "metadata": {
    "id": "041a1163"
   },
   "outputs": [],
   "source": [
    "# see SELFIES\n",
    "selfies = []\n",
    "for selfie in output[:5]:\n",
    "    vectorized = []\n",
    "    for token in selfie:\n",
    "        v = np.zeros(42)\n",
    "        v[token] = 1\n",
    "        vectorized.append(v)\n",
    "    vectorized = np.array(vectorized)\n",
    "    selfie = vectorizer.devectorize(vectorized)\n",
    "    selfies.append(selfie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f697df",
   "metadata": {
    "id": "c3f697df"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xp8fh69W_hNo",
   "metadata": {
    "id": "Xp8fh69W_hNo"
   },
   "outputs": [],
   "source": [
    "class ConsciousCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConsciousCrossEntropy, self).__init__();\n",
    "        self.batch_size = 256\n",
    "        self.alphabet_len = 42\n",
    "        self.seq_len = 128\n",
    "        self.idx_ignore = 40 # index of token to ignore\n",
    "        self.ignore = self.prep_token_to_ignore()\n",
    "\n",
    "    def forward(self, target, predictions):\n",
    "        cross_entropy_loss = 0\n",
    "        for y_true, y in zip(target, predictions):\n",
    "            sequence_loss = 0\n",
    "            mask = self.prep_mask(y_true)\n",
    "            nops = torch.sum(mask)\n",
    "            product = torch.mul(y_true, y)\n",
    "            prob = torch.sum(product, dim=1)\n",
    "            loss = -torch.log(prob)\n",
    "            loss_masked = torch.mul(loss, mask)\n",
    "            sequence_loss = torch.sum(loss_masked)/(self.seq_len - nops)\n",
    "            cross_entropy_loss += sequence_loss\n",
    "        loss_value = cross_entropy_loss/self.batch_size\n",
    "        return loss_value\n",
    "\n",
    "    def prep_token_to_ignore(self):\n",
    "        ignore = torch.zeros(self.alphabet_len).to(device)\n",
    "        ignore[self.idx_ignore] = 1\n",
    "        ignore = ignore.unsqueeze(0).repeat(128,1)\n",
    "        return ignore\n",
    "\n",
    "    def prep_mask(self, y_true): \n",
    "        # look through target SELFIES sequence and prepare mask\n",
    "        # as a tensor of size [128] with 0s on [nop] symbol\n",
    "        # and 1s for all the other tokens\n",
    "        v1 = torch.zeros(self.alphabet_len).to(device)\n",
    "        v1[self.idx_ignore] = 1\n",
    "        m1 = v1.unsqueeze(0).repeat(y_true.shape[0], 1)\n",
    "        product = torch.mul(y_true, m1)\n",
    "        output = ~torch.sum(product, dim=1).bool()\n",
    "        output = output.float()\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00cca",
   "metadata": {
    "id": "f7b00cca"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "def train(train_loader, test_loader, device):\n",
    "    \n",
    "    # Setting common hyperparameters\n",
    "    EPOCHS = 5\n",
    "    hidden_size = 256\n",
    "    num_layers = 1\n",
    "    output_size = 42\n",
    "    learn_rate = 0.001\n",
    "    \n",
    "    # Define dataframe for training progess display\n",
    "    epochs_range = range(1,EPOCHS+1)\n",
    "    metrics = pd.DataFrame();\n",
    "    metrics['epoch'] = epochs_range\n",
    "    \n",
    "    # Define pyplot for plotting metrics\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(7, 3), layout=\"constrained\")\n",
    "    dh = display.display(fig, display_id=True)\n",
    "    \n",
    "    # Instantiating the model\n",
    "    model = EncoderDecoder(\n",
    "        fp_size=4860, \n",
    "        encoding_size=256, \n",
    "        hidden_size=256, \n",
    "        num_layers=1, \n",
    "        dropout=0.2).to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    criterion = ConsciousCrossEntropy()\n",
    "\n",
    "    # wandb config and init\n",
    "    config = dict()\n",
    "    config['learning rate'] = learn_rate\n",
    "    config['encoding size'] = model.encoding_size\n",
    "    config['criterion'] = criterion\n",
    "    config['optimizer'] = optimizer\n",
    "    config['num epochs'] = EPOCHS\n",
    "    config['Trainable parameters'] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    config['hidden size'] = model.hidden_size\n",
    "    config['Number of layers'] = num_layers\n",
    "    config['Dropout'] = model.decoder.dropout\n",
    "    config['Batch size'] = batch_size\n",
    "    wandb.init(project=\"vec2seq\", config=config)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of GRU\")\n",
    "    print(f\"Device: {device}\")\n",
    "    # Start training loop\n",
    "    for epoch in epochs_range:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_idx, (X,y) in enumerate(tqdm(train_loader)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X).to(device)\n",
    "            loss = criterion(y, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        # calculate loss and log to wandb\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        val_loss = evaluate(model, test_loader)\n",
    "        metrics_dict = {'epoch': epoch, \n",
    "                        'train_loss': avg_loss, \n",
    "                        'val_loss': val_loss}\n",
    "        wandb.log(metrics_dict)\n",
    "\n",
    "        model.train()\n",
    "        # Update metrics df\n",
    "        metrics = metrics.append(metrics_dict, ignore_index=True)\n",
    "        \n",
    "        # Display metrics\n",
    "        ax[0].clear()\n",
    "        ax[0].plot(metrics.epoch, metrics.train_loss)\n",
    "        ax[0].set_title('training loss')\n",
    "        ax[0].set_xlabel('epoch')\n",
    "        ax[0].set_ylabel('CrossEntropy')\n",
    "        ax[1].clear()\n",
    "        ax[1].plot(metrics.epoch, metrics.val_loss)\n",
    "        ax[1].set_title('validation loss')\n",
    "        ax[1].set_xlabel('epoch')\n",
    "        ax[1].set_ylabel('CrossEntropy')\n",
    "        dh.update(fig)\n",
    "    plt.close()\n",
    "    wandb.finish()\n",
    "    return model\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    criterion = ConsciousCrossEntropy()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (X, y) in enumerate(test_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(X).to(device)\n",
    "        loss = criterion(y, output)\n",
    "        epoch_loss += loss.item()\n",
    "    avg_loss = epoch_loss / len(test_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874519b",
   "metadata": {
    "id": "c874519b"
   },
   "source": [
    "# Init and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839d044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0839d044",
    "outputId": "a499479c-a090-43f0-fb5c-8f442270e719"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: <ipython-input-45-36f7ade8c842> 45 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1152, in init\n",
      "    run = wi.init()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 601, in init\n",
      "    manager._inform_init(settings=self.settings, run_id=self.settings.run_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py\", line 208, in _inform_init\n",
      "    svc_iface._svc_inform_init(settings=settings, run_id=run_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/service/service_sock.py\", line 38, in _svc_inform_init\n",
      "    self._sock_client.send(inform_init=inform_init)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 211, in send\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setting up manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inform_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py\u001b[0m in \u001b[0;36m_inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0msvc_iface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_service_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0msvc_iface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_svc_inform_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/service/service_sock.py\u001b[0m in \u001b[0;36m_svc_inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minform_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minform_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, inform_init, inform_start, inform_attach, inform_finish, inform_teardown)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unmatched\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a05ea8c7c618>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-36f7ade8c842>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dropout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Batch size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vec2seq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Abnormal program exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"An unexpected error occurred\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror_seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: An unexpected error occurred"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8614d46",
   "metadata": {
    "id": "f8614d46"
   },
   "outputs": [],
   "source": [
    "# save model just in case\n",
    "torch.save(model.state_dict(), './GRU_data/test1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad90c0",
   "metadata": {
    "id": "2bad90c0"
   },
   "outputs": [],
   "source": [
    "#loaded_model = Autoencoder(4860, 300, 300, 42, 2, 0.0).to(device)\n",
    "#loaded_model.load_state_dict(torch.load('./GRU_data/model_h300_e500_teacher_forcing.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e768d4a",
   "metadata": {
    "id": "2e768d4a"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "x = x.to(device)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdfd19",
   "metadata": {
    "id": "9dbdfd19"
   },
   "outputs": [],
   "source": [
    "encoded, decoded = loaded_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6bfa9",
   "metadata": {
    "id": "bfe6bfa9"
   },
   "source": [
    "# GRU output to SELFIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab1202",
   "metadata": {
    "id": "2aab1202"
   },
   "outputs": [],
   "source": [
    "decoded_indices = torch.argmax(decoded.cpu(), dim=2)\n",
    "decoded_indices = decoded_indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1d92f",
   "metadata": {
    "id": "c4a1d92f"
   },
   "outputs": [],
   "source": [
    "# set largers value to 1 and others to 0\n",
    "decoded_indices = torch.argmax(decoded.cpu(), dim=2)\n",
    "decoded_indices = decoded_indices.numpy()\n",
    "selfies_out = []\n",
    "for i, original in zip(decoded_indices, y):\n",
    "    vectorized = []\n",
    "    #print(f'Decoded: {i}')\n",
    "    #convert to one-hot\n",
    "    for number in i:\n",
    "        v = np.zeros(42)\n",
    "        v[number] = 1\n",
    "        vectorized.append(v)\n",
    "    vectorized = np.array(vectorized)\n",
    "    selfies_out.append(vectorizer.devectorize(vectorized, remove_special=True))\n",
    "    print(f'Original: {vectorizer.devectorize(original.cpu().numpy())} \\n')\n",
    "    print(f'Decoded:  {vectorizer.devectorize(vectorized)}')\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efcd595",
   "metadata": {
    "id": "1efcd595"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "smiles = []\n",
    "for selfie in selfies_out:\n",
    "    smile = sf.decoder(selfie, attribute=False)\n",
    "    smiles.append(smile)\n",
    "\n",
    "ms = []\n",
    "for smile in smiles:\n",
    "    ms.append(Chem.MolFromSmiles(smile))\n",
    "Draw.MolToImage(ms[5], size=(800, 800), kekulize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
