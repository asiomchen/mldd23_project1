{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from fp_gen import KlekFPGenerator, MACCSFPGenerator, SubFPGenerator\n",
    "from DataProc import *\n",
    "import pandas.api.types as ptypes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06:17:59] SMILES Parse Error: syntax error while parsing: SMILES\n",
      "[06:17:59] SMILES Parse Error: Failed parsing SMILES 'SMILES' for input: 'SMILES'\n",
      "C:\\Users\\matit\\AppData\\Local\\Temp\\ipykernel_16680\\557390353.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['fps'] = list(map(sparse_to_dense, fps))\n"
     ]
    }
   ],
   "source": [
    "generator = KlekFPGenerator(n_jobs=os.cpu_count())\n",
    "data = pd.read_csv('../original_datasets/artificial/d2_artificial.csv', chunksize=500, names=['SMILES'])\n",
    "\n",
    "for i, chunk in enumerate(data):\n",
    "    chunk = chunk[chunk['SMILES'].apply(could_be_valid)]\n",
    "    mols = list(map(Chem.MolFromSmiles, chunk['SMILES']))\n",
    "    fps = generator.transform(mols)\n",
    "    chunk['fps'] = list(map(sparse_to_dense, fps))\n",
    "    if i == 0:\n",
    "        chunk.to_csv('../original_datasets/artificial/d2_klek_artificial.csv', index=False)\n",
    "    else: # append if already exists, otherwise without else firts chunk will be written twice\n",
    "        with open('../original_datasets/artificial/d2_klek_artificial.csv', 'a') as f:\n",
    "            chunk.to_csv(f, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 5ht1a protein\n",
      "Loaded data for 5ht7 protein\n",
      "Loaded data for beta2 protein\n",
      "Loaded data for d2 protein\n",
      "Loaded data for h1 protein\n"
     ]
    }
   ],
   "source": [
    "proteins = ['5ht1a','5ht7','beta2','d2','h1']\n",
    "for protein in proteins:\n",
    "    data = DataProcessor(protein)\n",
    "    data.load_data()\n",
    "    data.remove_missing()\n",
    "    data.remove_duplicates()\n",
    "    data.add_classification()\n",
    "    data.write_cleaned()\n",
    "    data.write_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../original_datasets/klek_clean/5ht1a_klek_balanced.csv ../original_datasets/parquet_clean/5ht1a_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/5ht7_klek_balanced.csv ../original_datasets/parquet_clean/5ht7_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/beta2_klek_balanced.csv ../original_datasets/parquet_clean/beta2_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/d2_klek_balanced.csv ../original_datasets/parquet_clean/d2_klek_balanced.parquet\n",
      "../original_datasets/klek_clean/h1_klek_balanced.csv ../original_datasets/parquet_clean/h1_klek_balanced.parquet\n"
     ]
    }
   ],
   "source": [
    "def csv_to_parquet(read_path, write_path):\n",
    "    data = pd.read_csv(read_path, sep=',')\n",
    "    data.to_parquet(write_path)\n",
    "\n",
    "read_paths = [f'../original_datasets/klek_clean/{x}_klek_balanced.csv' for x in proteins]\n",
    "write_paths = [f'../original_datasets/parquet_clean/{x}_klek_balanced.parquet' for x in proteins]\n",
    "    \n",
    "for read_path, write_path in zip(read_paths, write_paths):\n",
    "    print(read_path, write_path)\n",
    "    csv_to_parquet(read_path, write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
