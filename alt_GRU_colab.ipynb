{"cells":[{"cell_type":"code","execution_count":131,"id":"6ef6f3f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ef6f3f5","executionInfo":{"status":"ok","timestamp":1686162931150,"user_tz":-120,"elapsed":7,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"b7ffd9f9-98f1-4977-8fed-0201cd7e382b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":131}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data_utils\n","import torch.functional as F\n","import numpy as np\n","import pandas as pd\n","import time\n","import random\n","from tqdm import tqdm_notebook\n","import matplotlib.pyplot as plt\n","from IPython import display\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":10,"id":"0412b0d9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0412b0d9","executionInfo":{"status":"ok","timestamp":1686161028486,"user_tz":-120,"elapsed":23211,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"53ccd269-2cf4-451f-b91e-ae1e622d2771"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastparquet\n","  Downloading fastparquet-2023.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.5.3)\n","Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.22.4)\n","Collecting cramjam>=2.3 (from fastparquet)\n","  Downloading cramjam-2.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n","Installing collected packages: cramjam, fastparquet\n","Successfully installed cramjam-2.6.2 fastparquet-2023.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting selfies\n","  Downloading selfies-2.1.1-py3-none-any.whl (35 kB)\n","Installing collected packages: selfies\n","Successfully installed selfies-2.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=417e65930b67930d3d9b6ee44053f7bd180545889d52cb16c597d802a35380b8\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"]}],"source":["!pip install fastparquet\n","!pip install selfies\n","!pip install wandb"]},{"cell_type":"markdown","id":"f16dfcb1","metadata":{"id":"f16dfcb1"},"source":["# Data prep"]},{"cell_type":"code","execution_count":132,"id":"f1581e2f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1581e2f","executionInfo":{"status":"ok","timestamp":1686162940730,"user_tz":-120,"elapsed":3484,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"dc456442-a6a6-4a2e-e6c1-ef37cab9a6a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#somehow load two parquet files into coxd ale to jeszcze lab - drive?\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":133,"id":"974fa697","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"974fa697","executionInfo":{"status":"ok","timestamp":1686162942228,"user_tz":-120,"elapsed":258,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"32b9fa3d-b1a2-4b66-e6fc-2b27d19aa1f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["250k_klek.csv\t  combined_klek.parquet\n","250k_selfies.csv  combined_selfies.parquet\n"]}],"source":["!ls '/content/drive/My Drive/GRU_data'"]},{"cell_type":"code","execution_count":null,"id":"8a3fbcdb","metadata":{"id":"8a3fbcdb"},"outputs":[],"source":["import selfies as sf\n","data = pd.read_parquet('/content/drive/My Drive/GRU_data/combined_selfies.parquet')\n","alphabet = sf.get_alphabet_from_selfies(data.selfies)\n","#alphabet.add(\"[nop]\") # [nop] is a special padding symbol\n","alphabet.add(\"[start]\")\n","alphabet.add(\"[end]\")\n","alphabet.add(\"[nop]\")\n","alphabet = list(sorted(alphabet))\n","pad_to_len = max(sf.len_selfies(s) for s in data.selfies) + 10\n","print(\"Pad to len:\", pad_to_len)\n","symbol_to_idx = {s: i for i, s in enumerate(alphabet)}\n","idx2char = {i: s for i, s in enumerate(alphabet)}"]},{"cell_type":"code","execution_count":null,"id":"72177872","metadata":{"id":"72177872"},"outputs":[],"source":["len(alphabet)"]},{"cell_type":"code","execution_count":null,"id":"f55a6d94","metadata":{"id":"f55a6d94"},"outputs":[],"source":["import re\n","class SELFIESVectorizer:\n","    def __init__(self, alphabet, pad_to_len=None):\n","        self.alphabet = alphabet\n","        self.char2idx = {s: i for i, s in enumerate(alphabet)}\n","        self.idx2char = {i: s for i, s in enumerate(alphabet)}\n","        self.pad_to_len = pad_to_len\n","    def vectorize(self, selfie, no_special=False):\n","        ''' Vectorize a list of SMILES strings to a numpy array of shape (len(smiles), embed, len(charset))'''\n","        if no_special:\n","            splited = self.split_selfi(selfie)\n","        elif self.pad_to_len is None:\n","            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]']\n","        else:\n","            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]'] + ['[nop]'] * (self.pad_to_len - len(self.split_selfi(selfie)) - 2)\n","        X = np.zeros((len(splited), len(self.alphabet)))\n","        for i in range(len(splited)):\n","            X[i, self.char2idx[splited[i]]] = 1\n","        return X\n","    def devectorize(self, ohe, remove_special=False):\n","        ''' Devectorize a numpy array of shape (len(smiles), embed, len(charset)) to a list of SMILES strings'''\n","        selfie_str = ''\n","        for j in range(ohe.shape[0]):\n","            idx = np.argmax(ohe[j, :])\n","            if remove_special and (self.idx2char[idx] == '[start]' or self.idx2char[idx] == '[end]'):\n","                continue\n","            selfie_str += self.idx2char[idx]\n","        return selfie_str\n","    def idxize(self, selfie, no_special=False):\n","        if no_special:\n","            splited = self.split_selfi(selfie)\n","        else:\n","            splited = ['[start]'] + self.split_selfi(selfie) + ['[end]'] + ['[nop]'] * (self.pad_to_len - len(self.split_selfi(selfie)) - 2)\n","        return np.array([self.char2idx[s] for s in splited])\n","    def deidxize(self, idx):\n","        return \"\".join([self.idx2char[i] for i in idx])\n","    def split_selfi(self, selfie):\n","        pattern = r'(\\[[^\\[\\]]*\\])'\n","        return re.findall(pattern, selfie)"]},{"cell_type":"code","execution_count":14,"id":"70924816","metadata":{"id":"70924816","executionInfo":{"status":"ok","timestamp":1686161071014,"user_tz":-120,"elapsed":4,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["vectorizer = SELFIESVectorizer(alphabet, pad_to_len=pad_to_len)"]},{"cell_type":"code","execution_count":15,"id":"ae464156","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae464156","executionInfo":{"status":"ok","timestamp":1686161072224,"user_tz":-120,"elapsed":3,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"c5dff6a6-9403-40ed-83f5-da2667599bf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["SELFIE: [C][C][=C][C][=C][Branch2][Ring1][=N][C][=Branch1][C][=O][N][C][=C][C][=C][Branch1][=C][S][=Branch1][C][=O][=Branch1][C][=O][N][=C][Branch1][C][N][N][C][=C][Ring1][=N][C][=C][Ring2][Ring1][=Branch1]\n","OHE: [[0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 1. 0.]\n"," [0. 0. 0. ... 0. 1. 0.]\n"," [0. 0. 0. ... 0. 1. 0.]]\n","Devectorized: [start][C][C][=C][C][=C][Branch2][Ring1][=N][C][=Branch1][C][=O][N][C][=C][C][=C][Branch1][=C][S][=Branch1][C][=O][=Branch1][C][=O][N][=C][Branch1][C][N][N][C][=C][Ring1][=N][C][=C][Ring2][Ring1][=Branch1][end][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop]\n"]}],"source":["test_selfie = data.selfies[0]\n","ohe = vectorizer.vectorize(test_selfie)\n","print(\"SELFIE:\", test_selfie)\n","print(\"OHE:\", ohe)\n","print(\"Devectorized:\", vectorizer.devectorize(ohe))"]},{"cell_type":"code","execution_count":16,"id":"1b95bc0d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b95bc0d","executionInfo":{"status":"ok","timestamp":1686161074175,"user_tz":-120,"elapsed":6,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"df68e202-53ab-450b-81ff-c7872701d812"},"outputs":[{"output_type":"stream","name":"stdout","text":["IDX: [41 23 23  9 23  9 18 33 11 23  7 23 12 29 23  9 23  9 17  9 35  7 23 12\n","  7 23 12 29  9 17 23 29 29 23  9 33 11 23  9 34 33  7 39 40 40 40 40 40\n"," 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n"," 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n"," 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40]\n","Deidxized: [start][C][C][=C][C][=C][Branch2][Ring1][=N][C][=Branch1][C][=O][N][C][=C][C][=C][Branch1][=C][S][=Branch1][C][=O][=Branch1][C][=O][N][=C][Branch1][C][N][N][C][=C][Ring1][=N][C][=C][Ring2][Ring1][=Branch1][end][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop][nop]\n"]}],"source":["idx = vectorizer.idxize(test_selfie)\n","print(\"IDX:\", idx)\n","print(\"Deidxized:\", vectorizer.deidxize(idx))"]},{"cell_type":"code","execution_count":17,"id":"948ff36b","metadata":{"id":"948ff36b","executionInfo":{"status":"ok","timestamp":1686161075986,"user_tz":-120,"elapsed":241,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class GRUDataset(Dataset):\n","    def __init__(self, smiles_fp, selfies, vectorizer):\n","        self.smiles_fp = pd.read_csv(smiles_fp, sep=',', nrows=50000)\n","        self.selfies = pd.read_csv(selfies, nrows=500000)\n","        self.X = self.prepare_X(self.smiles_fp)\n","        self.X = np.array([self.reconstruct_fp(fp) for fp in self.X])\n","        self.y = self.prepare_y(self.selfies)\n","        self.vectorizer = vectorizer\n","    def __len__(self):\n","        return len(self.smiles_fp)\n","    def __getitem__(self, idx):\n","        raw_selfie = self.y[idx][0]\n","        vectorized_selfie = self.vectorizer.vectorize(raw_selfie)\n","        # esentially, we want to predict the next symbol in the SELFIE and offset the target by one makes teaching forcing implicit\n","        vectorized_selfie = vectorized_selfie[1:, :]\n","        return torch.from_numpy(self.X[idx]).float(), torch.from_numpy(vectorized_selfie).float()\n","\n","    @staticmethod\n","    def prepare_X(smiles_fp):\n","        fps = smiles_fp.fps.apply(eval).apply(lambda x: np.array(x, dtype=int))\n","        return fps\n","    @staticmethod\n","    def prepare_y(selfies):\n","        return selfies.values\n","    @staticmethod\n","    def reconstruct_fp(fp, length=4860):\n","        fp_rec = np.zeros(length)\n","        fp_rec[fp] = 1\n","        return fp_rec"]},{"cell_type":"code","execution_count":18,"id":"6538d564","metadata":{"id":"6538d564","executionInfo":{"status":"ok","timestamp":1686161079219,"user_tz":-120,"elapsed":247,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","class GRUDatasetv2(Dataset):\n","    def __init__(self, smiles_fp, selfies, vectorizer):\n","        self.smiles_fp = pd.read_csv(smiles_fp, nrows=50000)\n","        self.selfies = pd.read_csv(selfies, nrows=50000)\n","        # self.X = self.prepare_X(self.smiles_fp)\n","        # self.X = np.array([self.reconstruct_fp(fp) for fp in self.X])\n","        self.selfies= self.prepare_y(self.selfies)\n","        self.vectorizer = vectorizer\n","    def __len__(self):\n","        return len(self.smiles_fp)\n","    def __getitem__(self, idx):\n","        raw_selfie = self.selfies[idx][0]\n","        vectorized_selfie = self.vectorizer.idxize(raw_selfie)\n","        # esentially, we want to predict the next symbol in the SELFIE and offset the target by one makes teaching forcing implicit\n","        vectorized_selfie = vectorized_selfie\n","        raw_X = self.smiles_fp.fps[idx]\n","        X = np.array(eval(raw_X), dtype=int)\n","        X_reconstructed = self.reconstruct_fp(X)\n","\n","        return torch.from_numpy(X_reconstructed).float(), torch.from_numpy(vectorized_selfie).long()\n","\n","    @staticmethod\n","    def prepare_X(smiles_fp):\n","        fps = smiles_fp.fps.apply(eval).apply(lambda x: np.array(x, dtype=int))\n","        return fps\n","    @staticmethod\n","    def prepare_y(selfies):\n","        return selfies.values\n","    @staticmethod\n","    def reconstruct_fp(fp, length=4860):\n","        fp_rec = np.zeros(length)\n","        fp_rec[fp] = 1\n","        return fp_rec"]},{"cell_type":"code","execution_count":19,"id":"062168b4","metadata":{"id":"062168b4","executionInfo":{"status":"ok","timestamp":1686161083709,"user_tz":-120,"elapsed":2163,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["dataset = GRUDatasetv2('/content/drive/My Drive/GRU_data/250k_klek.csv', '/content/drive/My Drive/GRU_data/250k_selfies.csv', vectorizer)\n","train_size = int(0.9 * len(dataset))\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"]},{"cell_type":"code","execution_count":20,"id":"9172cd73","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9172cd73","executionInfo":{"status":"ok","timestamp":1686161083710,"user_tz":-120,"elapsed":7,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"7bbdf176-0bfc-4647-9fcf-44ad774e0f96"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n"," tensor([41, 23, 29, 35,  7, 23, 12,  7, 23, 12, 23,  9, 23,  9, 18, 33, 34, 23,\n","         23, 23, 11, 23, 17,  8, 23,  9, 23,  9, 29, 11, 33,  7, 11, 31, 33, 31,\n","         23,  9, 34, 33, 33, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]))"]},"metadata":{},"execution_count":20}],"source":["train_dataset[1]"]},{"cell_type":"code","execution_count":21,"id":"3a16a986","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a16a986","executionInfo":{"status":"ok","timestamp":1686161085877,"user_tz":-120,"elapsed":241,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"f2bde771-1321-4a4e-c72a-0a5f4f60dcc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset size: 50000\n","Train size: 45000\n","Test size: 5000\n"]}],"source":["print(\"Dataset size:\", len(dataset))\n","print(\"Train size:\", len(train_dataset))\n","print(\"Test size:\", len(test_dataset))"]},{"cell_type":"code","execution_count":117,"id":"da4f014e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da4f014e","executionInfo":{"status":"ok","timestamp":1686162674319,"user_tz":-120,"elapsed":252,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"5da54a79-6a1d-4b5f-b477-f3da58ba7479"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 119])"]},"metadata":{},"execution_count":117}],"source":["batch_size = 64\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, drop_last=True)\n","src, trg = next(iter(train_loader))\n","trg.shape"]},{"cell_type":"code","execution_count":23,"id":"810d9808","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"810d9808","executionInfo":{"status":"ok","timestamp":1686161089416,"user_tz":-120,"elapsed":4,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"5d860828-5189-4c42-8389-6f3e3a39857d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n"," tensor([41, 23, 23, 17, 23, 23, 17, 23, 23, 23,  9, 23,  9, 31, 23,  9, 17, 35,\n","         23, 23,  7, 23, 12, 29, 23,  9, 23,  9, 23,  9, 33,  7, 25, 23, 33, 35,\n","          9, 34, 33, 34, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n","         40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]))"]},"metadata":{},"execution_count":23}],"source":["dataset[0]"]},{"cell_type":"markdown","id":"02f39daf","metadata":{"id":"02f39daf"},"source":["# NN architecture"]},{"cell_type":"code","execution_count":123,"id":"8248e95c","metadata":{"id":"8248e95c","executionInfo":{"status":"ok","timestamp":1686162875733,"user_tz":-120,"elapsed":253,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["class EncoderNet(nn.Module):\n","    def __init__(self, fp_size, encoding_size):\n","        super(EncoderNet, self).__init__()\n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(fp_size, 2048)\n","        self.fc2 = nn.Linear(2048, 1024)\n","        self.fc3 = nn.Linear(1024, 512)\n","        self.fc4 = nn.Linear(512, 256)\n","        self.fc5 = nn.Linear(256, encoding_size)\n","    def forward(self, x):\n","        out = self.relu(self.fc1(x))\n","        out = self.relu(self.fc2(out))\n","        out = self.relu(self.fc3(out))\n","        out = self.relu(self.fc4(out))\n","        out = self.relu(self.fc5(out))\n","        return out\n","\n","\n","class DecoderNet(nn.Module):\n","    def __init__(self, dictionary_size, encoding_size, hidden_size, num_layers, drop_prob):\n","        super(DecoderNet, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.drop_prob = drop_prob\n","        self.embedding = nn.Embedding(dictionary_size, encoding_size)\n","        self.gru = nn.GRU(encoding_size, hidden_size, num_layers, dropout=drop_prob, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, dictionary_size)\n","        self.max_len = vectorizer.pad_to_len\n","\n","    def forward(self, input, hidden):\n","        prediction, hidden = self.gru(input, hidden)\n","        prediction = self.fc(prediction)\n","        return prediction, hidden\n","    \n","class Autoencoder(nn.Module):\n","    def __init__(self, input_size=4860, \n","                 encoding_size=128, \n","                 dictionary_size=len(alphabet), \n","                 hidden_size=128, \n","                 num_layers=2, \n","                 teacher_forcing_ratio=0.5,\n","                 drop_prob=0.2):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = EncoderNet(input_size, encoding_size)\n","        self.num_layers = num_layers  \n","        self.hidden_size = hidden_size\n","        self.encoding_size = encoding_size\n","        self.decoder = DecoderNet(dictionary_size, encoding_size, hidden_size, num_layers, drop_prob)\n","        self.teacher_forcing_ratio = teacher_forcing_ratio\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=None):\n","        teacher_forcing_ratio = self.teacher_forcing_ratio if teacher_forcing_ratio is None else teacher_forcing_ratio\n","        # if in evaluation mode we don't use teacher forcing\n","        if not self.training:\n","            teacher_forcing_ratio = 0\n","        batch_size = src.shape[0]\n","        trg_vocab_size = self.decoder.fc.out_features\n","        outputs = []\n","        hidden = torch.zeros(self.num_layers, src.shape[0], self.hidden_size)\n","        input = self.encoder(src).unsqueeze(1)\n","        for t in range(1, self.encoding_size):\n","            input[:, :, t]\n","            print(f'Input shape: {input.shape}')\n","            print(f'Hidden shape: {hidden.shape}')\n","            output, hidden = self.decoder(input, hidden)\n","            outputs.append(output)\n","            teacher_force = 0 #random.random() < teacher_forcing_ratio\n","            top1 = torch.argmax(output, dim=2)\n","        outputs = torch.cat(outputs, dim=1)\n","        return outputs"]},{"cell_type":"code","execution_count":64,"id":"1f37f3df","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f37f3df","executionInfo":{"status":"ok","timestamp":1686161526418,"user_tz":-120,"elapsed":256,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"4f5021c7-4b91-4a11-82b8-2d6142b424f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 4860])"]},"metadata":{},"execution_count":64}],"source":["encoder = EncoderNet(4860, 128).to(device)\n","decoder = DecoderNet(dictionary_size=len(alphabet), \n","                     emb_size=128, \n","                     hidden_size=128, \n","                     num_layers=2, \n","                     drop_prob=0.2).to(device)\n","test_batch = next(iter(train_loader))[0].to(device)\n","test_batch.shape"]},{"cell_type":"code","execution_count":82,"id":"5ab9b122","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ab9b122","executionInfo":{"status":"ok","timestamp":1686161756639,"user_tz":-120,"elapsed":252,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"3498bac5-1a2b-455b-c44f-66854e05eaa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test batch shape: torch.Size([64, 4860])\n","Encoded shape: torch.Size([64, 128])\n"]}],"source":["print(f'Test batch shape: {test_batch.shape}')\n","encoded = encoder(test_batch)\n","print(f'Encoded shape: {encoded.shape}')"]},{"cell_type":"code","execution_count":66,"id":"54cfdfba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54cfdfba","executionInfo":{"status":"ok","timestamp":1686161529579,"user_tz":-120,"elapsed":5,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"ce18308d-3dc5-4183-def8-e04ecfed92bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Start token shape: torch.Size([64, 1])\n"]}],"source":["start_token = vectorizer.idxize('[start]', no_special=True)\n","start_token = torch.from_numpy(start_token).long().to(device).unsqueeze(0)\n","start_token = start_token.repeat(test_batch.shape[0], 1)\n","print(f'Start token shape: {start_token.shape}')\n","#print(f'Start token: {start_token}')"]},{"cell_type":"code","source":["encoded = encoded.unsqueeze(1)\n","encoded.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o133FAbnMYM","executionInfo":{"status":"ok","timestamp":1686161532878,"user_tz":-120,"elapsed":254,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"d5082c3e-e80a-4db9-ab77-777b6077a889"},"id":"8o133FAbnMYM","execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 1, 128])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","execution_count":107,"id":"09ccfcc7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"09ccfcc7","executionInfo":{"status":"error","timestamp":1686162528991,"user_tz":-120,"elapsed":476,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"a7cd20fe-4580-4373-c132-a3c5c9152d36"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-107-ab56e5971602>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Encoded shape: {encoded.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Decoded shape: {decoded.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Hidden shape: {hidden.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-aca207dfc22e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                         raise RuntimeError(\n\u001b[0m\u001b[1;32m    976\u001b[0m                             f\"For unbatched 2-D input, hx should also be 2-D but got {hx.dim()}-D tensor\")\n\u001b[1;32m    977\u001b[0m                     \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"]}],"source":["hidden = torch.zeros(2, 64, 128).to(device)\n","decoded, hidden = decoder(encoded, hidden)\n","print(f'Encoded shape: {encoded.shape}')\n","print(f'Decoded shape: {decoded.shape}')\n","print(f'Hidden shape: {hidden.shape}')"]},{"cell_type":"code","execution_count":124,"id":"f2893d40","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2893d40","executionInfo":{"status":"ok","timestamp":1686162879520,"user_tz":-120,"elapsed":365,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"24411adf-29bd-4fb1-b572-48812a6e464f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 4860])"]},"metadata":{},"execution_count":124}],"source":["model = Autoencoder().to(device)\n","test_src = next(iter(train_loader))[0].to(device)\n","test_trg = next(iter(train_loader))[1].to(device)\n","test_src.shape"]},{"cell_type":"code","source":["outputs = model(src=test_src, trg=test_trg)\n","print(f'Outputs shape: {outputs.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6-wuiP4QNU8","executionInfo":{"status":"ok","timestamp":1686162883547,"user_tz":-120,"elapsed":515,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"412eb4f3-32e4-440c-ea6a-cdf12cf767a2"},"id":"F6-wuiP4QNU8","execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Input shape: torch.Size([64, 1, 128])\n","Hidden shape: torch.Size([2, 64, 128])\n","Outputs shape: torch.Size([64, 127, 42])\n"]}]},{"cell_type":"code","execution_count":126,"id":"3163467c","metadata":{"id":"3163467c","executionInfo":{"status":"ok","timestamp":1686162889212,"user_tz":-120,"elapsed":259,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["outputs_fixed = outputs"]},{"cell_type":"code","execution_count":127,"id":"041a1163","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"041a1163","executionInfo":{"status":"ok","timestamp":1686162892070,"user_tz":-120,"elapsed":287,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"4ba3c403-0bea-4440-9230-40ec7bee9414"},"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape: torch.Size([127, 42])\n","Output: tensor([ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 31, 31, 31, 31,  6, 31,\n","        31,  6,  6, 31,  6,  6,  6, 31,  6,  6,  6,  6, 31, 31, 31,  6, 31,  6,\n","        31, 31, 31, 31, 31, 31, 31,  6, 31,  6,  6,  6,  6,  6, 31,  6,  6,  6,\n","        31,  6,  6,  6,  6,  6,  6,  6, 31,  6,  6, 31, 31,  6, 31,  6, 31, 31,\n","        31,  6,  6,  6,  6,  6,  6, 31,  6, 31,  6,  6,  6, 31,  6,  6,  6,  6,\n","        31, 31,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n","         6,  6, 31,  6, 31, 31, 31, 31, 31,  6, 31, 31, 31,  6,  6,  6,  6,  6,\n","         6])\n"]}],"source":["# get first output from batch\n","output = outputs_fixed[0]\n","print(f'Output shape: {output.shape}')\n","print(f'Output: {torch.argmax(output, dim=1)}')"]},{"cell_type":"markdown","id":"c3f697df","metadata":{"id":"c3f697df"},"source":["# Training"]},{"cell_type":"code","execution_count":128,"id":"ce412c1f","metadata":{"id":"ce412c1f","executionInfo":{"status":"ok","timestamp":1686162899086,"user_tz":-120,"elapsed":241,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}}},"outputs":[],"source":["def train_epoch(autoencoder, dataloader, learning_rate):\n","    autoencoder.train()\n","    criterion = nn.CrossEntropyLoss(ignore_index=vectorizer.char2idx['[nop]'])\n","    optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n","    epoch_loss = 0\n","    for batch_idx, (src, trg) in enumerate(tqdm(dataloader)):\n","        src = src.to(device)\n","        trg = trg.to(device)\n","        optimizer.zero_grad()\n","        output = autoencoder(src, trg)\n","        trg = trg[:, 1:]\n","        output = output.permute(0, 2, 1)\n","        loss = criterion(output, trg)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","    avg_loss = epoch_loss / len(dataloader)\n","\n","    return avg_loss\n","  \n","def evaluate(autoencoder, dataloader):\n","    autoencoder.eval()\n","    criterion = nn.CrossEntropyLoss(ignore_index=vectorizer.char2idx['[nop]'])\n","    epoch_loss = 0\n","    for batch_idx, (src, trg) in enumerate(dataloader):\n","        src = src.to(device)\n","        trg = trg.to(device)\n","        output = autoencoder(src, trg)\n","        trg = trg[:, 1:]\n","        output = output.permute(0, 2, 1)\n","        loss = criterion(output, trg)\n","        epoch_loss += loss.item()\n","    avg_loss = epoch_loss / len(dataloader)\n","    return avg_loss"]},{"cell_type":"code","execution_count":129,"id":"0839d044","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":980},"id":"0839d044","executionInfo":{"status":"error","timestamp":1686162903542,"user_tz":-120,"elapsed":1483,"user":{"displayName":"Hubert Rybka","userId":"05494656428041101228"}},"outputId":"ea7a5487-849c-4115-cc43-6b255ea102d2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 700x300 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-129-c70a3fd39c52>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-128-0f64b0664ac7>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(autoencoder, dataloader, learning_rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 700x300 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["batch_size = 256\n","num_epochs = 10\n","\n","epochs = []\n","train_losses = []\n","val_losses = []\n","\n","fig, ax = plt.subplots(ncols=2, figsize=(7, 3), layout=\"constrained\")\n","dh = display.display(fig, display_id=True)\n","\n","for epoch in range(num_epochs):\n","  train_loss = train_epoch(model, train_loader, learning_rate=0.001)\n","  val_loss = evaluate(model, test_loader)\n","  train_losses.append(train_loss)\n","  val_losses.append(val_loss)\n","  epochs.append(epoch+1)\n","\n","  ax[0].clear()\n","  ax[0].plot(epochs, train_losses)\n","  ax[0].set_title('training loss')\n","  ax[0].set_xlabel('epoch')\n","  ax[0].set_ylabel('CrossEntropy')\n","  ax[1].clear()\n","  ax[1].plot(epochs, val_losses)\n","  ax[1].set_title('validation loss')\n","  ax[1].set_xlabel('epoch')\n","  ax[1].set_ylabel('CrossEntropy')\n","  dh.update(fig)\n","plt.close()"]},{"cell_type":"code","execution_count":null,"id":"f8614d46","metadata":{"id":"f8614d46"},"outputs":[],"source":["# save model just in case\n","#torch.save(model.state_dict(), './GRU_data/test1.pt')"]},{"cell_type":"code","execution_count":null,"id":"2bad90c0","metadata":{"id":"2bad90c0"},"outputs":[],"source":["#loaded_model = Autoencoder(4860, 300, 300, 42, 2, 0.0).to(device)\n","#loaded_model.load_state_dict(torch.load('./GRU_data/model_h300_e500_teacher_forcing.pt'))"]},{"cell_type":"code","execution_count":null,"id":"2e768d4a","metadata":{"id":"2e768d4a"},"outputs":[],"source":["x, y = next(iter(test_loader))\n","x = x.to(device)\n","x.size()"]},{"cell_type":"code","execution_count":null,"id":"9dbdfd19","metadata":{"id":"9dbdfd19"},"outputs":[],"source":["encoded, decoded = loaded_model(x)"]},{"cell_type":"markdown","id":"bfe6bfa9","metadata":{"id":"bfe6bfa9"},"source":["# GRU output to SELFIES"]},{"cell_type":"code","execution_count":null,"id":"2aab1202","metadata":{"id":"2aab1202"},"outputs":[],"source":["decoded_indices = torch.argmax(decoded.cpu(), dim=2)\n","decoded_indices = decoded_indices.numpy()"]},{"cell_type":"code","execution_count":null,"id":"c4a1d92f","metadata":{"id":"c4a1d92f"},"outputs":[],"source":["# set largers value to 1 and others to 0\n","decoded_indices = torch.argmax(decoded.cpu(), dim=2)\n","decoded_indices = decoded_indices.numpy()\n","selfies_out = []\n","for i, original in zip(decoded_indices, y):\n","    vectorized = []\n","    #print(f'Decoded: {i}')\n","    #convert to one-hot\n","    for number in i:\n","        v = np.zeros(42)\n","        v[number] = 1\n","        vectorized.append(v)\n","    vectorized = np.array(vectorized)\n","    selfies_out.append(vectorizer.devectorize(vectorized, remove_special=True))\n","    print(f'Original: {vectorizer.devectorize(original.cpu().numpy())} \\n')\n","    print(f'Decoded:  {vectorizer.devectorize(vectorized)}')\n","    print('------------------')"]},{"cell_type":"code","execution_count":null,"id":"1efcd595","metadata":{"id":"1efcd595"},"outputs":[],"source":["from rdkit import Chem\n","from rdkit.Chem import Draw\n","\n","smiles = []\n","for selfie in selfies_out:\n","    smile = sf.decoder(selfie, attribute=False)\n","    smiles.append(smile)\n","\n","ms = []\n","for smile in smiles:\n","    ms.append(Chem.MolFromSmiles(smile))\n","Draw.MolToImage(ms[5], size=(800, 800), kekulize=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}