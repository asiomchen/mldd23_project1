{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "552f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5da7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerprintGenerator():\n",
    "    \n",
    "    def __init__(self, protein, fingerprint):\n",
    "        sys.path.append('..')\n",
    "        self.proteins_ = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']  # allowed proteins\n",
    "        self.fingerprints_ = ['Klek', 'Sub', 'MACCS']  # allowed fingerprints\n",
    "        \n",
    "        self.protein = protein\n",
    "        self.fingerprint = fingerprint\n",
    "        \n",
    "        self.df = None\n",
    "        \n",
    "        self.data_paths = {\n",
    "            '5ht1a': './smiles/5ht1a_smiles.csv',\n",
    "            '5ht7': './smiles/5ht7_smiles.csv',\n",
    "            'beta2': './smiles/beta2_smiles2.csv',\n",
    "            'd2': './smiles/d2_smiles.csv',\n",
    "            'h1': './smiles/h1_smiles.csv'\n",
    "        }\n",
    "        \n",
    "        self.keys_paths = {\n",
    "            'Klek': './keys/KlekFP_keys.txt',\n",
    "            'Sub': './keys/SubFP_keys.txt',\n",
    "            'MACCS': './keys/MACCSFP_keys.txt'\n",
    "        }\n",
    "        \n",
    "        self.load_data()\n",
    "        \n",
    "            \n",
    "    def load_data(self):\n",
    "        if self.protein in self.proteins_:\n",
    "            self.df = pd.read_csv(self.data_paths[self.protein], sep=',', header=0, names=[\"SMILES\", \"Ki\"])\n",
    "            self.df['Ki'] = self.df['Ki'].astype('float')\n",
    "        else:\n",
    "            print('Protein not found, please check the spelling and allowed proteins')\n",
    "        \n",
    "    def generate_fingerprint(self, mol, smarts):\n",
    "        \n",
    "        fingerprint = DataStructs.ExplicitBitVect(len(smarts))\n",
    "        \n",
    "        for key, bit_position in smarts.items():\n",
    "            pattern = Chem.MolFromSmarts(key)\n",
    "            if mol.HasSubstructMatch(pattern):\n",
    "                fingerprint.SetBit(bit_position)\n",
    "        \n",
    "        return fingerprint\n",
    "    \n",
    "    def smiles_to_fingerprint(self):\n",
    "        \n",
    "        with open(self.keys_paths[self.fingerprint], 'r') as f:\n",
    "            smarts = f.readlines()\n",
    "        \n",
    "        smarts_dict = {}\n",
    "        \n",
    "        for index, key in enumerate(smarts):\n",
    "            smarts_dict[key] = index\n",
    "        \n",
    "        fingerprints = []\n",
    "        \n",
    "        for index, row in self.df.iterrows():\n",
    "            smiles = row['SMILES']\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            fp = self.generate_fingerprint(mol, smarts_dict)\n",
    "            fingerprints.append(fp)\n",
    "        \n",
    "        self.df[self.fingerprint] = fingerprints\n",
    "    \n",
    "    def move_fingerprints(self):\n",
    "        unpacked_fp = {}\n",
    "        for index, row in self.df.iterrows():\n",
    "            fingerprint = row[self.fingerprint]\n",
    "            unpacked_fingerprint = [x for x in fingerprint]\n",
    "            \n",
    "        unpacked_df = pd.DataFrame(unpacked_fp)\n",
    "        print(unpacked_df)\n",
    "        self.df = self.df.join(unpacked_df)\n",
    "    \n",
    "    def save_fingerprints(self):\n",
    "        write_path = './data_new_FP/' + self.protein + '_' + self.fingerprint + '.csv'\n",
    "        self.df.to_csv(write_path, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9cfdc78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1  2\n",
      "0     0  1  1\n",
      "1     0  0  0\n",
      "2     0  0  0\n",
      "3     0  0  0\n",
      "4     0  0  0\n",
      "...  .. .. ..\n",
      "4855  0  0  0\n",
      "4856  0  0  0\n",
      "4857  0  0  0\n",
      "4858  0  0  0\n",
      "4859  0  0  0\n",
      "\n",
      "[4860 rows x 3 columns]\n",
      "                                              SMILES     Ki   \n",
      "0                                  NCCCNCCSP(O)(O)=O    NaN  \\\n",
      "1  CCc1cc2CC(Cc2cc1CC)NC[C@H](O)c1ccc(O)c2NC(=O)C...   45.0   \n",
      "2                  CC(C)(C)NCC(O)c1cc(Cl)c(N)c(Cl)c1  570.0   \n",
      "\n",
      "                                                Klek  0  1  2  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0  1  1  \n",
      "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0  0  0  \n",
      "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0  0  0  \n"
     ]
    }
   ],
   "source": [
    "protein = 'beta2'\n",
    "data = FingerprintGenerator(protein, 'Klek')\n",
    "data.smiles_to_fingerprint()\n",
    "data.move_fingerprints()\n",
    "print(data.df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f784b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4860\n"
     ]
    }
   ],
   "source": [
    "print(len(data.df['Klek'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c84e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor():\n",
    "    \n",
    "    \"\"\"\n",
    "    This class loads molecular fingerprints into a DataFrame and performs clean-up on them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protein : str\n",
    "        The protein name, one of ['5ht1a', '5ht7', 'beta2', 'd2', 'h1'].\n",
    "    fingerprint : str\n",
    "        The fingerprint type, one of ['Klek', 'Sub', 'MACCS'].\n",
    "    y_col : str, optional\n",
    "        The name of the column representing the dependent variable, default is 'Ki'.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_paths_ : dict\n",
    "        A dictionary containing the paths to the fingerprint files.\n",
    "    proteins_ : list of str\n",
    "        The list of valid protein names.\n",
    "    fingerprints_ : list of str\n",
    "        The list of valid fingerprint types.\n",
    "    protein : str\n",
    "        The protein name.\n",
    "    fingerprint : str\n",
    "        The fingerprint type.\n",
    "    path : str\n",
    "        The path to the fingerprint file.\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the loaded fingerprint data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    remove_missing()\n",
    "        Removes rows with missing values in the dependent variable column.\n",
    "    remove_duplicates()\n",
    "        Removes duplicate rows in the DataFrame.\n",
    "    remove_redundant()\n",
    "        Removes redundant columns in the DataFrame.\n",
    "    convert_data()\n",
    "        Converts the data types of the columns in the DataFrame.\n",
    "    add_classification(threshold)\n",
    "        Adds a Class column to the DataFrame based on the threshold parameter.\n",
    "    write_cleaned()\n",
    "        Writes the cleaned DataFrame to a csv file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, protein, fingerprint, y_col='Ki'):\n",
    "        sys.path.append('..')\n",
    "        self.data_paths_ = {\n",
    "    '5ht1a_Klek' : './datasets/5ht1a_KlekFP.csv',\n",
    "    '5ht1a_MACCS' : './datasets/5ht1a_MACCSFP.csv',\n",
    "    '5ht1a_Sub' : './datasets/5ht1a_SubFP.csv',\n",
    "    '5ht7_Klek' : './datasets/5ht7_KlekFP.csv',\n",
    "    '5ht7_MACCS' : './datasets/5ht7_MACCSFP.csv',\n",
    "    '5ht7_Sub' : './datasets/5ht7_SubFP.csv',\n",
    "    'beta2_Klek' : './datasets/beta2_KlekFP.csv',\n",
    "    'beta2_MACCS' : './datasets/beta2_MACCSFP.csv',\n",
    "    'beta2_Sub' : './datasets/beta2_SubFP.csv',\n",
    "    'd2_Klek' : './datasets/d2_KlekFP.csv',\n",
    "    'd2_MACCS' : './datasets/d2_MACCSFP.csv',\n",
    "    'd2_Sub' : './datasets/d2_SubFP.csv',\n",
    "    'h1_Klek' : './datasets/h1_KlekFP.csv',\n",
    "    'h1_MACCS' : './datasets/h1_MACCSFP.csv',\n",
    "    'h1_Sub' : './datasets/h1_SubFP.csv'\n",
    "    }\n",
    "            \n",
    "        self.proteins_ = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']\n",
    "        self.fingerprints_ = ['Klek', 'Sub', 'MACCS']\n",
    "        self.y_col = y_col\n",
    "        self.missing = None\n",
    "        self.duplicated = None\n",
    "        self.redundant = None\n",
    "        \n",
    "        self.protein = protein\n",
    "        self.fingerprint = fingerprint\n",
    "        self.path = self.protein + '_' + self.fingerprint\n",
    "        if self.path in self.data_paths_.keys():\n",
    "            self.df = pd.read_csv(self.data_paths_[self.path])\n",
    "            print(f'{self.fingerprint} FP for protein {self.protein} loaded')\n",
    "        else:\n",
    "            self.df = None\n",
    "            print(\"Protein and fingerprint combination not found\")\n",
    "        \n",
    "        \n",
    "    def remove_missing(self):\n",
    "        print(f'The initial size of dataset: {len(self.df)}')\n",
    "        missing = self.df[self.y_col].isnull()\n",
    "        zero_or_neg = self.df[self.y_col] <= 0\n",
    "        to_remove = pd.Series([a or b for a, b in zip(missing,zero_or_neg)])\n",
    "        print(f'The percent of rows with missing {self.y_col} values: {to_remove.sum()/len(self.df)*100:.2f} %')\n",
    "        self.df = self.df[~to_remove]\n",
    "        print(f'New size of the dataset: {len(self.df)}')\n",
    "        self.missing = int(to_remove.sum())\n",
    "        \n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        print(f'The initial size of dataset: {len(self.df)}')\n",
    "        duplicates = self.df.duplicated(keep = 'first')\n",
    "        print(f'The percent of duplicated rows: {duplicates.sum()/len(self.df)*100:.2f} %')\n",
    "        self.df = self.df[~duplicates]\n",
    "        print(f'New size of the dataset: {len(self.df)}')\n",
    "        self.duplicated = int(duplicates.sum())\n",
    "        \n",
    "        \n",
    "    def remove_redundant(self):\n",
    "        col1 = len(self.df.columns)\n",
    "        selection = [True if sum > 0 else False for sum in self.df.sum(axis=0)]\n",
    "        self.df = self.df.loc[:, selection]\n",
    "        col2 = len(self.df.columns)\n",
    "        print(f'There were {col1-col2} redundant columns in the dataset.')\n",
    "        self.redundant = int(col1 - col2)\n",
    "        \n",
    "        \n",
    "    def convert_data(self):\n",
    "        self.df[self.y_col] = self.df[self.y_col].astype(float)\n",
    "        columns = self.df.columns[1:]\n",
    "        self.df[columns] = self.df[columns].astype(int)\n",
    "        \n",
    "        \n",
    "    def add_classification(self, threshold = 100):\n",
    "        classes = [1 if x < threshold else 0 for x in self.df[self.y_col]]\n",
    "        self.df.insert(1, \"Class\", classes)\n",
    "        print(f'The percent of compounds classified as active is {self.df[\"Class\"].sum()/len(self.df)*100:.2f} %')\n",
    "        \n",
    "                \n",
    "    def write_cleaned(self):\n",
    "        write_path = './cleaned_datasets/' + self.path + '_clean.csv'\n",
    "        self.df.to_csv(path_or_buf=write_path, sep=',', index=False)\n",
    "        print(f'Cleaned file saved at {write_path}')\n",
    "    \n",
    "    \n",
    "    def return_parameters(self): # zwraca listę list dotyczącą ile czego brakowało/usunięto w kolejności wczytania do klasy\n",
    "        parameters = []\n",
    "        parameters.append(self.missing)\n",
    "        parameters.append(self.duplicated)\n",
    "        parameters.append(self.redundant)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec6953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACCS FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.79 %\n",
      "New size of the dataset: 5629\n",
      "The initial size of dataset: 5629\n",
      "The percent of duplicated rows: 8.33 %\n",
      "New size of the dataset: 5160\n",
      "There were 18 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.18 %\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "data = DataProcessor(protein='5ht1a', fingerprint='MACCS')\n",
    "data.remove_missing()\n",
    "data.remove_duplicates()\n",
    "data.remove_redundant()\n",
    "data.add_classification()\n",
    "data.convert_data()\n",
    "\n",
    "# data.write_cleaned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4c71d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klek FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.79 %\n",
      "New size of the dataset: 5629\n",
      "The initial size of dataset: 5629\n",
      "The percent of duplicated rows: 7.66 %\n",
      "New size of the dataset: 5198\n",
      "There were 3263 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.10 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht1a_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.79 %\n",
      "New size of the dataset: 5629\n",
      "The initial size of dataset: 5629\n",
      "The percent of duplicated rows: 10.23 %\n",
      "New size of the dataset: 5053\n",
      "There were 190 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.60 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht1a_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.79 %\n",
      "New size of the dataset: 5629\n",
      "The initial size of dataset: 5629\n",
      "The percent of duplicated rows: 8.33 %\n",
      "New size of the dataset: 5160\n",
      "There were 18 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 58.18 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht1a_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 6.18 %\n",
      "New size of the dataset: 2945\n",
      "There were 3508 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 51.34 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht7_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 8.89 %\n",
      "New size of the dataset: 2860\n",
      "There were 204 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 51.89 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht7_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 7.45 %\n",
      "New size of the dataset: 2905\n",
      "There were 21 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 51.81 %\n",
      "Cleaned file saved at ./cleaned_datasets/5ht7_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 3.70 %\n",
      "New size of the dataset: 781\n",
      "There were 3800 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 41.87 %\n",
      "Cleaned file saved at ./cleaned_datasets/beta2_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 6.29 %\n",
      "New size of the dataset: 760\n",
      "There were 199 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 42.37 %\n",
      "Cleaned file saved at ./cleaned_datasets/beta2_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 4.44 %\n",
      "New size of the dataset: 775\n",
      "There were 16 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 42.19 %\n",
      "Cleaned file saved at ./cleaned_datasets/beta2_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.09 %\n",
      "New size of the dataset: 10746\n",
      "The initial size of dataset: 10746\n",
      "The percent of duplicated rows: 6.09 %\n",
      "New size of the dataset: 10092\n",
      "There were 3060 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 36.58 %\n",
      "Cleaned file saved at ./cleaned_datasets/d2_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.09 %\n",
      "New size of the dataset: 10746\n",
      "The initial size of dataset: 10746\n",
      "The percent of duplicated rows: 10.50 %\n",
      "New size of the dataset: 9618\n",
      "There were 169 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 37.72 %\n",
      "Cleaned file saved at ./cleaned_datasets/d2_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.09 %\n",
      "New size of the dataset: 10746\n",
      "The initial size of dataset: 10746\n",
      "The percent of duplicated rows: 7.57 %\n",
      "New size of the dataset: 9932\n",
      "There were 14 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 36.93 %\n",
      "Cleaned file saved at ./cleaned_datasets/d2_MACCS_clean.csv\n",
      "\n",
      "\n",
      "Klek FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 3.50 %\n",
      "New size of the dataset: 1680\n",
      "There were 3581 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 38.21 %\n",
      "Cleaned file saved at ./cleaned_datasets/h1_Klek_clean.csv\n",
      "\n",
      "\n",
      "Sub FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 9.76 %\n",
      "New size of the dataset: 1571\n",
      "There were 205 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 39.34 %\n",
      "Cleaned file saved at ./cleaned_datasets/h1_Sub_clean.csv\n",
      "\n",
      "\n",
      "MACCS FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 5.40 %\n",
      "New size of the dataset: 1647\n",
      "There were 18 redundant columns in the dataset.\n",
      "The percent of compounds classified as active is 38.43 %\n",
      "Cleaned file saved at ./cleaned_datasets/h1_MACCS_clean.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# przygotowanie danych\n",
    "\n",
    "proteins = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']\n",
    "keys = ['Klek', 'Sub', 'MACCS']\n",
    "\n",
    "deleted = [] # przechowywanie informacji o zmianach\n",
    "\n",
    "for protein in proteins:\n",
    "        for key in keys:\n",
    "            data = DataProcessor(protein=protein, fingerprint=key)\n",
    "            data.remove_missing()\n",
    "            data.remove_duplicates()\n",
    "            data.remove_redundant()\n",
    "            data.add_classification()\n",
    "            data.convert_data()\n",
    "            # parameters = data.return_parameters()\n",
    "            # deleted.append(parameters)\n",
    "            data.write_cleaned()\n",
    "            print('\\n')\n",
    "            del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc2dc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACCS FP for protein 5ht1a loaded\n",
      "The initial size of dataset: 5851\n",
      "The percent of rows with missing Ki values: 3.79 %\n",
      "New size of the dataset: 5629\n",
      "The initial size of dataset: 5629\n",
      "The percent of duplicated rows: 8.33 %\n",
      "New size of the dataset: 5160\n",
      "MACCS FP for protein 5ht7 loaded\n",
      "The initial size of dataset: 3266\n",
      "The percent of rows with missing Ki values: 3.89 %\n",
      "New size of the dataset: 3139\n",
      "The initial size of dataset: 3139\n",
      "The percent of duplicated rows: 7.45 %\n",
      "New size of the dataset: 2905\n",
      "MACCS FP for protein beta2 loaded\n",
      "The initial size of dataset: 1667\n",
      "The percent of rows with missing Ki values: 51.35 %\n",
      "New size of the dataset: 811\n",
      "The initial size of dataset: 811\n",
      "The percent of duplicated rows: 4.44 %\n",
      "New size of the dataset: 775\n",
      "MACCS FP for protein d2 loaded\n",
      "The initial size of dataset: 11821\n",
      "The percent of rows with missing Ki values: 9.09 %\n",
      "New size of the dataset: 10746\n",
      "The initial size of dataset: 10746\n",
      "The percent of duplicated rows: 7.57 %\n",
      "New size of the dataset: 9932\n",
      "MACCS FP for protein h1 loaded\n",
      "The initial size of dataset: 2615\n",
      "The percent of rows with missing Ki values: 33.42 %\n",
      "New size of the dataset: 1741\n",
      "The initial size of dataset: 1741\n",
      "The percent of duplicated rows: 5.40 %\n",
      "New size of the dataset: 1647\n"
     ]
    }
   ],
   "source": [
    "# Zliczenia dla MACCSÓW, jeżeli FP to powinno Ci wypluć normalnie wszystkie dane ile czego w nich jest; raczej nie próbuj \n",
    "# loopa bo się potem dalsze zepsują\n",
    "\n",
    "proteins = ['5ht1a', '5ht7', 'beta2', 'd2', 'h1']\n",
    "data = []\n",
    "new = pd.DataFrame()\n",
    "\n",
    "for protein in proteins:\n",
    "    df = DataProcessor(protein, \"MACCS\")\n",
    "    df.remove_missing()\n",
    "    df.remove_duplicates()\n",
    "    x = list(df.df.columns[1:])\n",
    "    y = list(df.df.iloc[:, 1:].sum().astype('int'))\n",
    "    frame = pd.DataFrame({'Key' : x, 'Count' : y})\n",
    "    freq = list(frame['Count'])\n",
    "    leng = np.max(freq)\n",
    "    new_values = []\n",
    "    for value in freq:\n",
    "        new_values.append(value/leng*100)\n",
    "    frame['Freq'] = pd.Series(new_values).astype('float')\n",
    "    data.append(frame)\n",
    "    new[protein] = y\n",
    "new['keys'] = x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
